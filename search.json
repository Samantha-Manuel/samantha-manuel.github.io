[
  {
    "objectID": "comparison.html",
    "href": "comparison.html",
    "title": "Review of Two Data Visualizations",
    "section": "",
    "text": "First Chart Citation:\nKirk, David S. and Papachristos, Andrew V., 2011. Cultural Mechanisms and the Persistence of Neighborhood Violence. American Journal of Sociology, [online] 116(4), pp. 1190-1233.\nHere is a description from Kirk and Papachristos (2011) of their data visualization chart:\n“In figure 4 we use the standardized coefficients from table 4 to compare the effects of concentrated poverty, proportion youth, tolerance of deviance, collective efficacy, and legal cynicism on the persistence of homicide. Through this analysis, we seek to determine which among these correlates of homicide are crucial for understanding why homicide persists in some neighborhoods over time. The bars displayed in this chart represent the association between homicide in a focal neighborhood (in terms of standard deviations) and each respective measure in the focal neighborhood. Not surprisingly, the proportion of youths in a neighborhood in 1990 strongly predicts the persistence of homicide from the early 1990s to the early 2000s. Homicide statistics show that young adults (ages 18–24) have the highest victimization and offending rates by a large margin (Fox and Zawitz 1999, 2004). Thus, if we assume that neighborhoods with high proportions of youths (under 18) in 1990 subsequently had high proportions of young adults (18–24) over the course of the ensuing decade, then such neighborhoods would be exposed to heightened risks of homicide victimization and offending because of the age distribution of the neighborhood population.” (Kirk and Papachristos 2011 p. 1226)\n\n\n\n\n\nThe authors continued to conclude:\n“Most crucial for our core arguments, figure 4 reveals quite vividly the importance of legal cynicism for explaining the persistence of neighborhood violence. Even more so than collective efficacy, legal cynicism explains why rates of homicide remained stable in some Chicago neighborhoods (e.g., Bronzeville) during the 1990s when homicide declined dramatically citywide.” (Kirk and Papachristos 2011 p. 1226)\nSecond chart citation:\nMassoglia, Michael, Firebaugh, Glenn, and Warner, Cody. 2012. Racial Variation in the Effect of Incarceration on Neighborhood Attainment. American Sociological Review, [online] 78(1), pp. 142-165.\nHere is a description from Massoglia, Firebaugh, and Warner (2012) of their data visualization chart:\n“We measure neighborhood disadvantage using census tract characteristics identified as important aspects of neighborhood socioeconomic disadvantage: poverty, joblessness, female-headed families, and receipt of public assistance… For our analysis we created a disadvantage index score for every census tract by first standardizing and then summing the measures at each wave. Because we are summing standardized scores, the result is an index with a mean of roughly zero at each time point. Higher scores on this scale reflect residence in a more disadvantaged neighborhood, so a positive coefficient for our post-prison measures would indicate that ex-inmates tend to live in worse neighborhoods following prison.” ( pp. 149-150)\n\n\n\n\n\nThey continued to describe their findings from the chart:\n“We can draw on the descriptive statistics for a preliminary examination of ex-inmate neighborhood conditions; Figure 2 plots disadvantage scores broken down by ex-inmate status and race/ethnicity. Because we use a standardized index, the zero point on the x-axis reflects the sample mean, with scores above zero reflecting higher-than-average levels of disadvantage. Two findings stand out. First, there are striking racial disparities in neighborhood attainment, with blacks and Hispanics who have never served time in prison living, on average, in more disadvantaged neighborhoods than whites who have been in prison. Second, in initial support of Hypothesis 1, there appears to be a detrimental effect of incarceration.” (Massoglia, Firebaugh, and Warner 2012 p. 152)"
  },
  {
    "objectID": "assign05.html",
    "href": "assign05.html",
    "title": "EPPS 6356 Assignment 5",
    "section": "",
    "text": "# Setting up the new R environment, starting fresh, click run!\nrm(list=ls())\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# Horizontal Bar Plot\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\ncounts <- table(mtcars$gear)\nbarplot(counts, main=\"Car Distribution\", horiz=TRUE, names.arg=c(\"3 Gears\", \"4 Gears\", \"5 Gears\"))\n\n\n\n# Column Chart\nsummary_data <- tapply(mtcars$hp, list(cylinders = mtcars$cyl, transmission = mtcars$am), FUN = mean, na.rm = TRUE)\n\npar(mar = c(5, 5, 4, 10))\n\nbarplot(summary_data, xlab = \"Transmission type\",\n        main = \"Horsepower Mean\",\n        col = rainbow(3),\n        beside = TRUE,\n        legend.text = rownames(summary_data),\n        args.legend = list(title = \"Cylinders\", x = \"topright\",\n                           inset = c(-0.20, 0)))\n\n\n\n# Radar Chart\nlibrary(fmsb)\nexam_scores <- data.frame(\n    row.names = c(\"Student.1\", \"Student.2\", \"Student.3\"),\n      Biology = c(7.9, 3.9, 9.4),\n      Physics = c(10, 20, 0),\n        Maths = c(3.7, 11.5, 2.5),\n        Sport = c(8.7, 20, 4),\n      English = c(7.9, 7.2, 12.4),\n    Geography = c(6.4, 10.5, 6.5),\n          Art = c(2.4, 0.2, 9.8),\n  Programming = c(0, 0, 20),\n        Music = c(20, 20, 20)\n)\n\n# Define the variable ranges: maximum and minimum\nmax_min <- data.frame(\n  Biology = c(20, 0), Physics = c(20, 0), Maths = c(20, 0),\n  Sport = c(20, 0), English = c(20, 0), Geography = c(20, 0),\n  Art = c(20, 0), Programming = c(20, 0), Music = c(20, 0)\n)\nrownames(max_min) <- c(\"Max\", \"Min\")\n\n# Bind the variable ranges to the data\ndf2 <- rbind(max_min, exam_scores)\ndf2\n\n          Biology Physics Maths Sport English Geography  Art Programming Music\nMax          20.0      20  20.0  20.0    20.0      20.0 20.0          20    20\nMin           0.0       0   0.0   0.0     0.0       0.0  0.0           0     0\nStudent.1     7.9      10   3.7   8.7     7.9       6.4  2.4           0    20\nStudent.2     3.9      20  11.5  20.0     7.2      10.5  0.2           0    20\nStudent.3     9.4       0   2.5   4.0    12.4       6.5  9.8          20    20\n\n# Generating radar chart\nstudent1_data <- df2[c(\"Max\", \"Min\", \"Student.1\"), ]\nradarchart(student1_data)"
  },
  {
    "objectID": "assign04.html",
    "href": "assign04.html",
    "title": "EPPS 6356 Assignment 4",
    "section": "",
    "text": "The data set used aimed to observe the net domestic immigration rates (NDIR), which represents the net movement of people into and out of a state, over the period 1990-1994 divided by the population of the state. Alaska and Hawaii are excluded from the analysis because the environments of these states are significantly different from the other 48, and their locations present certain barriers to immigration. Eleven predictor variables thought to influence NDIR are defined in Table 1.4 below.\n\n\n\n\n\nIndependent Variable (IV): Regional Tax Brackets\nDependent Variable (DV): NDIR (Net Domestic Immigration Rate)\nLegend of Dummy DV (NDIR):\nImmigration into the Region - “1”\nEmigration out of the Region - “0”\nBelow is our analysis of our generated charts:\n\n\n\n\n\nFigure 1: The Effect of Tax Brackets on NDIR.\nThe first and second tax bracket shows a higher number of people immigrating in this tax bracket than emigrating. However, the third and fourth tax brackets have lower immigration rates than emigration rates. This shows there is no general trend of NDIR in relation to all four tax brackets, as seen in Figure 1.\nWhat can be observed is that the lower the value of NDIR, the more people are emigrating out of the state, the higher the value of NDIR, the more people are immigrating into the state.\n\n\n\n\n\nFigure 2: The Effect of Region on NDIR.\n\n\n\n\n\nFigure 3: The Effect of Region on Tax Brackets.\nThe immigration/emigration graph organized by region, suggests that people in the Northeast region almost exclusively emigrate, as seen in Figures 2 and 3 above. The effects of region on tax bracket model shows that none of the participants responded that they belonged in either of the first two tax brackets. This could also be the reason that we do not see Northeast noticeably represented in the aggregated model, Figure 4.\n\n\n\n\n\nFigure 4: The Effect of Tax Brackets on NDIR by Region.\n\n# Setting up the new R environment, starting fresh, click run! \n(list=ls())\n\ncharacter(0)\n\n# Setting up the working directory, click run!\nsetwd(\"/Users/sami_manuel/Documents/Fall 2022/EPPS 6356/samantha-manuel.github.io\")\n\n# Reading the file, click run!\nHW4 <- read.delim(\"HW4data.txt\") \nhead(HW4)\n\n        State   NDIR Unemp  Wage Crime Income Metrop Poor Taxes Educ BusFail\n1     Alabama  17.47   6.0 10.75   780  27196   67.4 16.4  1553 66.9    0.20\n2     Arizona  49.60   6.4 11.17   715  31293   84.7 15.9  2122 78.7    0.51\n3    Arkansas  23.62   5.3  9.65   593  25565   44.7 15.3  1590 66.3    0.08\n4  California -37.21   8.6 12.44  1078  35331   96.7 17.9  2396 76.2    0.63\n5    Colorado  53.17   4.2 12.27   567  37833   81.8  9.0  2092 84.4    0.42\n6 Connecticut -38.41   5.6 13.53   456  41097   95.7 10.8  3334 79.2    0.33\n   Temp    Region\n1 62.77     South\n2 61.09      West\n3 59.57     South\n4 59.25      West\n5 43.43      West\n6 48.63 Northeast\n\n#Turning on the packages required for HW4, click run!\nlibrary(\"Hmisc\") \n\nLoading required package: lattice\n\n\nLoading required package: survival\n\n\nLoading required package: Formula\n\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\nlibrary(\"tidyverse\")\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n✔ purrr   0.3.4      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::src()       masks Hmisc::src()\n✖ dplyr::summarize() masks Hmisc::summarize()\n\n#Identifying the mean of HW4 for later usage: mean= 10.88854, click run!\nmean(HW4$NDIR)\n\n[1] 10.88854\n\n#Creating a new dummy variable, i.e. above 1 or below 0 mean, click run!\nHW4$NDIR_dummy <- ifelse(HW4$NDIR>=10.88854, 1, 0)\n\n#Creating taxes into an ordinal variable with 4 equally sized bins, click run!\nHW4$tax_ord <- cut2(HW4$Taxes, m=12)\n\n#Creating cross tabulation, click run!\ntable(HW4$NDIR_dummy,HW4$tax_ord)\n\n   \n    [1535,1853) [1853,2126) [2126,2371) [2371,3655]\n  0           5           4           7          10\n  1           7           8           5           2\n\n#Creating bar plot, click run!\nbarplot(table(HW4$NDIR_dummy,HW4$tax_ord), beside=TRUE, main= \"The Effect of Tax Brackets on NDIR\", xlab= \"Tax Brackets\", ylab= \"NDIR\", legend = TRUE)\n\n\n\nbarplot(table(HW4$NDIR_dummy,HW4$Region), beside=TRUE, main= \"The Effect of Region on NDIR\", xlab= \"Region\", ylab= \"NDIR\", legend = TRUE)\n\n\n\nbarplot(table(HW4$tax_ord,HW4$Region), beside=TRUE, main= \"The Effect of Region on Tax Brackets\", xlab= \"Region\", ylab= \"Tax Bracket Prevalence\", legend = TRUE)\n\n\n\n#Code for a Table with Embedded Charts\n#ggplot(df,aes(z,x,fill=as.factor(y)),angle=45,size=16)+ geom_bar(position=\"dodge\",stat=\"identity\") +facet_wrap(~z,nrow=3)\n\n#Creating Table with Embedded Charts, click run!\ndf <- data.frame(HW4) \np <- ggplot(df,aes(tax_ord,NDIR,fill=as.factor(Region)), angle=4, size=5)+ geom_bar(position=\"dodge\",stat=\"identity\") + facet_wrap(~tax_ord,nrow=3) \np + ggtitle(\"The Effect of Tax Brackets on NDIR by Region\") + xlab(\"Tax Brackets\") + ylab(\"NDIR\") + guides(fill=guide_legend(title=\"Region\")) + theme(axis.text.x = element_text(size = 6))"
  },
  {
    "objectID": "assign10.html",
    "href": "assign10.html",
    "title": "EPPS 6356 Assignment 10",
    "section": "",
    "text": "Write a review on visualization methods used in the presentation by the speaker and post on own GitHub website.\nHere is a link to the Colloquium: https://youtu.be/q-37SPXg7ko\nHere is my review of the Colloquium:\nI am going to be completely 100 percent candid: this colloquium was very challenging and difficult for me to understand. This is my very first semester intensively using R Studio and coding statistical analyses, let alone actually analyzing those statistical visualizations that I produce! Furthermore, I normally only am required to use generic regressions for my other courses; we really never really need to use other data visualization methods in order to demonstrate or display our important statistical findings. The fanciest thing I have ever done in R Studio prior to this course was an interaction effects plot, which honestly, I still have issues interpreting! All this is being said in order to give you an idea of my background knowledge of statistical methods, visualization, and interpretation skills: they are very minimal. Here is what I understood from the colloquium.\nDr. Patrick Brandt discussed multiple categories or “types” or models. These models were specific to “Statistics & Time Series for Policy Intervention & Change Identification”, which was the topic of the colloquium presentation. There were four types of models or visualizations that Dr. Brandt described: Type 0 (Basic Time Series), Type 1 (Binary Segmentation), Type 2 (Regularization and Fused Lasso), and Type 3 (Bayesian methods). Below are further descriptions of each method of these data visualizations:\nModel Type 0: Basic Time Series Model\n\nSimple model where the moment where the intervention occurs is identifiable.\nEasy for estimations.\nModels allow for many differences; Type 0 does not necessarily show distinct difference between multiple factors.\nExample used: Gas prices and seat belts; Salmonella in chicken breeding\n\nModel Type 1: Binary Segmentation\n\nThis model is commonly used for trends that are more complex, deterministic, or stochastic.\nWhat is stochastic? According to the Oxford Dictionary, “stochastic” means that the data/values are “randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely”.\nExample used: US Industrial Revolution and COVID.\n\nModel Type 2: L1/L0 Regularization and Fused Lasso\n\nThis type of model treats the issue by identifying a correct set of covariates from the possible sets of interventions presented by the data.\nThere are different ways to identify these covariates:\n\nSearch for each of the change-points individually.\nAssessing the probability of a change-point.\nFused Lasso Model: univariate vs. multivariate analyses\n(Safikhani et al. 2022).\n\n\nModel Type 3: Bayesian Methods\n\nThis method was mentioned briefly, but not discussed in detail.\nHere is a definition of Bayesian models from a quick Google search: “A Bayesian model is a statistical model where you use probability to represent all uncertainty within the model, both the uncertainty regarding the output but also the uncertainty regarding the input (aka parameters) to the model.”\n\n\n# Type 0: Times Series Model\n\nlapply(c(\"quantmod\", \"tidyverse\",\"TSstudio\"), require, character.only = TRUE)\n\nLoading required package: quantmod\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nLoading required package: tidyverse\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\nLoading required package: TSstudio\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\nlibrary(TSstudio)\nquantmod::getSymbols(\"TSLA\", src=\"yahoo\")\n\n[1] \"TSLA\"\n\nts_plot(TSLA$TSLA.Adjusted, \n        title = \"Tesla Stock prices\",\n        Ytitle = \"\")"
  },
  {
    "objectID": "assign06.html",
    "href": "assign06.html",
    "title": "EPPS 6356 Assignment 6",
    "section": "",
    "text": "https://samantha-manuel.shinyapps.io/samantha-manuel-assign06/"
  },
  {
    "objectID": "assign07.html",
    "href": "assign07.html",
    "title": "EPPS 6356 Assignment 7",
    "section": "",
    "text": "https://samantha-manuel.shinyapps.io/assign07/"
  },
  {
    "objectID": "assign03.html",
    "href": "assign03.html",
    "title": "EPPS 6356 Assignment 3",
    "section": "",
    "text": "a. Compare the regression models.\n\n\n\n\n\nFigure 1: Regression plot of X1 and Y1.\nAs seen in Figure 1, a regression plot is appropriate for data visualization and analysis. The plot points generally fit the regression line. However, because the plot points are very spaced out, the R^2 value may be very small, as the regression line does not fit plot points very well.\n\n\n\n\n\nFigure 2: Regression plot of X2 and Y2.\nAs seen in Figure 2, a regression plot is most likely not the best tool for data analysis. This is because all of the plot points resemble a parabolic function. For this reason, a different or supplementary data visualization/analysis tools may be required.\n\n\n\n\n\nFigure 3: Regression plot of X3 and Y3.\nFigure 3 is similar to Figure 1, in that a regression plot is appropriate for data visualization and analysis. The plot points generally fit the regression line, except for one outlier point at x=13. It may be beneficial to take this outlier out, and therefore visualize how much better the regression line would fit the data.\n\n\n\n\n\nFigure 4: Regression plot of X4 and Y4.\nLike Figure 2, a regression plot is most likely not the best tool for data analysis for Figure 4. This is because all of the plot points except for one are all at x=8. For this reason, different or supplementary data visualization/analysis tools are required.\nb. Compare different ways to create the plots (e.g. changing colors, line types, plot characters).\n\n\n\n\n\nFigure 5: Aggregate regression plots from X1-X4 and Y1-Y4.\nAs seen in Figure 5, all four regression plots were generated as a composite chart by using the code to “plot for a loop”. This composite/aggregate chart also was about to generate a title to describe the plots. This code was also able to add further design components such as regression line color, as well as plot point size, color, and shape.\n2.Can you finetune the charts without using other packages (consult RGraphics by Murrell).\n\n\n\n\n\nFigure 6: Finetuned aggregate regression plots for X1-X4 and Y1-Y4.\nAbove is Figure 6, which is the “finetuned” version of the regression plots for X1-X4 and Y1-Y4, using the RGraphics by Murrell. I changed the plot points to be smaller, so that the reader can more effectively read the charts and distinguish between the plot points. This is especially helpful for Plot 4, where many of the plot points are stacked on top of each other. Making the plot point sizes smaller also allows the reader to be able see the distance between plot points easier, as well. I also changed the color of the plot points and regression line to colors that are easier on the eye and less distracting.\n3.How about with ggplot2? (use tidyverse package)\nSee the code below to see how the ggplot2 function (attached to the tidyverse package) can be used to efficiently generate the four regression plots for Anscombe’s (1973) Quartlet. The generated chart is also seen below in Figure 7. This aggregate/composite plot was produced by using only two lines of code, instead of 13+ lines of code the traditional way without the ggplot2 function within the tidyverse package.\n\n\n\n\n\nFigure 7: Aggregate regression plots from X1-X4 and Y1-Y4 generated using the ggplot2 function.\n\n## Anscombe (1973) Quartlet\n\nrm(list=ls())\ndata(anscombe)  # Load Anscombe's data\nsummary(anscombe)\n\n       x1             x2             x3             x4           y1        \n Min.   : 4.0   Min.   : 4.0   Min.   : 4.0   Min.   : 8   Min.   : 4.260  \n 1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 8   1st Qu.: 6.315  \n Median : 9.0   Median : 9.0   Median : 9.0   Median : 8   Median : 7.580  \n Mean   : 9.0   Mean   : 9.0   Mean   : 9.0   Mean   : 9   Mean   : 7.501  \n 3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8   3rd Qu.: 8.570  \n Max.   :14.0   Max.   :14.0   Max.   :14.0   Max.   :19   Max.   :10.840  \n       y2              y3              y4        \n Min.   :3.100   Min.   : 5.39   Min.   : 5.250  \n 1st Qu.:6.695   1st Qu.: 6.25   1st Qu.: 6.170  \n Median :8.140   Median : 7.11   Median : 7.040  \n Mean   :7.501   Mean   : 7.50   Mean   : 7.501  \n 3rd Qu.:8.950   3rd Qu.: 7.98   3rd Qu.: 8.190  \n Max.   :9.260   Max.   :12.74   Max.   :12.500  \n\n# Create four model objects\nlm1 <- lm(y1 ~ x1, data=anscombe)\nsummary(lm1)\n\n\nCall:\nlm(formula = y1 ~ x1, data = anscombe)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92127 -0.45577 -0.04136  0.70941  1.83882 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0001     1.1247   2.667  0.02573 * \nx1            0.5001     0.1179   4.241  0.00217 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6665,    Adjusted R-squared:  0.6295 \nF-statistic: 17.99 on 1 and 9 DF,  p-value: 0.00217\n\nlm2 <- lm(y2 ~ x2, data=anscombe)\nsummary(lm2)\n\n\nCall:\nlm(formula = y2 ~ x2, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9009 -0.7609  0.1291  0.9491  1.2691 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)    3.001      1.125   2.667  0.02576 * \nx2             0.500      0.118   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.237 on 9 degrees of freedom\nMultiple R-squared:  0.6662,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002179\n\nlm3 <- lm(y3 ~ x3, data=anscombe)\nsummary(lm3)\n\n\nCall:\nlm(formula = y3 ~ x3, data = anscombe)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1586 -0.6146 -0.2303  0.1540  3.2411 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0025     1.1245   2.670  0.02562 * \nx3            0.4997     0.1179   4.239  0.00218 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6663,    Adjusted R-squared:  0.6292 \nF-statistic: 17.97 on 1 and 9 DF,  p-value: 0.002176\n\nlm4 <- lm(y4 ~ x4, data=anscombe)\nsummary(lm4)\n\n\nCall:\nlm(formula = y4 ~ x4, data = anscombe)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.751 -0.831  0.000  0.809  1.839 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   3.0017     1.1239   2.671  0.02559 * \nx4            0.4999     0.1178   4.243  0.00216 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.236 on 9 degrees of freedom\nMultiple R-squared:  0.6667,    Adjusted R-squared:  0.6297 \nF-statistic:    18 on 1 and 9 DF,  p-value: 0.002165\n\nplot(y1 ~ x1, data=anscombe) + abline(lm(y1 ~ x1, data=anscombe))\n\n\n\n\ninteger(0)\n\nplot(y2 ~ x2, data=anscombe) + abline(lm(y2 ~ x2, data=anscombe))\n\n\n\n\ninteger(0)\n\nplot(y3 ~ x3, data=anscombe) + abline(lm(y3 ~ x3, data=anscombe))\n\n\n\n\ninteger(0)\n\nplot(y4 ~ x4, data=anscombe) + abline(lm(y4 ~ x4, data=anscombe))\n\n\n\n\ninteger(0)\n\n## Fancy version (per help file)\n\nff <- y ~ x\nmods <- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] <- as.name(paste0(\"y\", i))\n  ##      ff[[3]] <- as.name(paste0(\"x\", i))\n  mods[[i]] <- lmi <- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(>F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(>|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nplot.new\n\nfunction () \n{\n    for (fun in getHook(\"before.plot.new\")) {\n        if (is.character(fun)) \n            fun <- get(fun)\n        try(fun())\n    }\n    .External2(C_plot_new)\n    grDevices:::recordPalette()\n    for (fun in getHook(\"plot.new\")) {\n        if (is.character(fun)) \n            fun <- get(fun)\n        try(fun())\n    }\n    invisible()\n}\n<bytecode: 0x7f8db7b0ce98>\n<environment: namespace:graphics>\n\nop <- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] <- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"darkorchid4\", pch = 23, bg = \"mediumpurple\", cex = 1,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"steelblue\")\n}\nmtext(\"Anscombe's 4 Regression Data Sets\", outer = TRUE, cex = 1.5)\n\n\n\npar(op)\n\n## 3.How about with ggplot2? (use tidyverse package)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(dplyr)\nlibrary(broom)\n\ntidy_anscombe <- anscombe %>%\n pivot_longer(cols = everything(),\n              names_to = c(\".value\", \"set\"),\n              names_pattern = \"(.)(.)\")\n\ntidy_anscombe\n\n# A tibble: 44 × 3\n   set       x     y\n   <chr> <dbl> <dbl>\n 1 1        10  8.04\n 2 2        10  9.14\n 3 3        10  7.46\n 4 4         8  6.58\n 5 1         8  6.95\n 6 2         8  8.14\n 7 3         8  6.77\n 8 4         8  5.76\n 9 1        13  7.58\n10 2        13  8.74\n# … with 34 more rows\n\nggplot(tidy_anscombe,\n       aes(x = x,\n           y = y)) +\n  geom_point() + \n  facet_wrap(~set) +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n#> `geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "assign02.html",
    "href": "assign02.html",
    "title": "EPPS 6356 Assignment 2",
    "section": "",
    "text": "Link: https://samantha-manuel.github.io/samantha-manuel.github.io-blog/\n2.Run Paul Murrell’s RGraphics basic R programs (murrell01.R in GitHub).\na. Be sure to run line by line and note the changes.\nb. Pay attention to the comments and address the question if there is one.\ni. plot(pressure, pch=16) # Can you change pch?\nYes, you can change the pch. Changing the pch alters the points on the plotline of the graph. For example, the value 16 for the pch are circles. If the pch is changed to 15, the circles change to squares.\nii. points(x, y1, pch=16, cex=3) # Try different cex value?\nThe cex value changes the size of the points on the plot line. The larger the cex value, the larger the points on the plot line.\niii. axis(1, at=seq(0, 16, 4)) # What is the first number standing for?\nThis command generates the x axis on the chart. The x axis is labelled “Travel Time in seconds”. This means that the first number on the x axis, 0, signifies when the time measurement begins; it is just before the responses are being recorded.\niv. Generations of these Murrell charts are below.\n\n\n\n\n\nFigure 1: Pressure plot with the pch value changed from 16 to 15.\n\n\n\n\n\nFigure 2: Bird 131 Travel scatterplot with the cex value changed from 2 to 3, as well as the “background color” of the white circles changed to grey circles.\n\n\n\n\n\nFigure 3: Histogram of Y.\n\n\n\n\n\nFigure 4: Barplot.\n\n\n\n\n\nFigure 5: Boxplot of Vitamin C dose (mg) on tooth growth/length.\n\n\n\n\n\nFigure 6: Perspective plot.\n\n\n\n\n\nFigure 7: Pie chart of pie sales.\nv. Try these functions using another dataset. Be sure to work on the layout and margins.\nSee Part C below. These functions will be used on the Happy Planet Index (HPI) data set.\nc. Plotting functions using the Happy Planet Index (HPI) data set.\n\n\n\n\n\n\n# Setting up the new R environment, starting fresh, click run!\nrm(list=ls())\n\n# Setting up the working directory, click run!\nsetwd(\"~/Documents/Fall 2022/EPPS 6356/samantha-manuel.github.io\")\n\n# Turning on the packages required for HW2, click run!\nlibrary(Hmisc)\n\nLoading required package: lattice\n\n\nLoading required package: survival\n\n\nLoading required package: Formula\n\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'Hmisc'\n\n\nThe following objects are masked from 'package:base':\n\n    format.pval, units\n\nlibrary(xlsx)\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n✔ purrr   0.3.4      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()    masks stats::filter()\n✖ dplyr::lag()       masks stats::lag()\n✖ dplyr::src()       masks Hmisc::src()\n✖ dplyr::summarize() masks Hmisc::summarize()\n\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(countrycode)\nlibrary(ggplot2)\n\n# Reading the file, click run!\nHPI <- read.xlsx(\"~/Documents/Fall 2022/EPPS 6356/samantha-manuel.github.io/happy-planet-index-2006-2020-public-data-set.xlsx\", sheetIndex = 2)\n\n#Remove first 7 rows and save as 'HPI2019', click run! \nHPI2019 <- HPI[-c(1:7),]\nview(HPI2019)\n\n#remove 3rd column ('NA..2') as it is not needed for further analysis, click run! \nHPI2019 <- HPI2019 %>%\n    select(-'NA..2')\n\n#Rename columns for simplicity, click run!\nHPI2019 <- HPI2019 %>%\n    rename(HPI_rank = 'NA.') %>%\n    rename(Country = 'X1..Rankings.for.all.countries..2006...2020') %>%\n    rename(ISO = 'NA..1') %>%\n    rename(Continent = 'NA..3') %>%\n    rename(Pop = 'NA..4') %>%\n    rename(Life_Exp = 'NA..5') %>%\n    rename(Wellbeing = 'NA..6') %>%\n    rename(Ecological_Footprint = 'NA..7') %>%\n    rename(HPI = 'NA..8') %>%\n    rename(Biocapacity = 'NA..9') %>%\n    rename(GDP_per_capita = 'NA..10')\n\n#Remove row with index number 8 so the data set starts with 'Costa Rica', click run! \nHPI2019 <- HPI2019[-1,]\n\n#Change to show a maximum of 15 digits, click run! \noptions(digits = 15)\n\n#Convert data type from character to numeric for selected columns, click run! \nHPI2019 <- HPI2019 %>%\n    mutate(HPI_rank = as.numeric(HPI_rank)) %>%\n    mutate(Pop = as.numeric(Pop)) %>%\n    mutate(Life_Exp = as.numeric(Life_Exp)) %>%\n    mutate(Wellbeing = as.numeric(Wellbeing)) %>%\n    mutate(Ecological_Footprint = as.numeric(Ecological_Footprint)) %>%\n    mutate(HPI = as.numeric(HPI)) %>%\n    mutate(Biocapacity = as.numeric(Biocapacity)) %>%\n    mutate(GDP_per_capita = as.numeric(GDP_per_capita))\n\nWarning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n#View cleaned data set, click run! \nstr(HPI2019)\n\n'data.frame':   152 obs. of  11 variables:\n $ HPI_rank            : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Country             : chr  \"Costa Rica\" \"Vanuatu\" \"Colombia\" \"Switzerland\" ...\n $ ISO                 : chr  \"CRI\" \"VUT\" \"COL\" \"CHE\" ...\n $ Continent           : chr  \"1\" \"8\" \"1\" \"3\" ...\n $ Pop                 : num  5048 300 50339 8591 17374 ...\n $ Life_Exp            : num  80.3 70.5 77.3 83.8 77 78.5 74.5 74.3 75.3 77.9 ...\n $ Wellbeing           : num  7 6.96 6.35 7.69 5.81 ...\n $ Ecological_Footprint: num  2.65 1.62 1.9 4.14 1.51 ...\n $ HPI                 : num  62.1 60.4 60.2 60.1 58.8 ...\n $ Biocapacity         : num  1.56 1.56 1.56 1.56 1.56 1.56 1.56 1.56 1.56 1.56 ...\n $ GDP_per_capita      : num  20297 3153 14625 68391 11375 ...\n\nhead(HPI2019)\n\n   HPI_rank     Country ISO Continent       Pop Life_Exp        Wellbeing\n9         1  Costa Rica CRI         1  5047.561     80.3 6.99761867523193\n10        2     Vanuatu VUT         8   299.882     70.5 6.95562031699646\n11        3    Colombia COL         1 50339.443     77.3 6.35029792785645\n12        4 Switzerland CHE         3  8591.361     83.8 7.69422101974487\n13        5     Ecuador ECU         1 17373.657     77.0 5.80913114547729\n14        6      Panama PAN         1  4246.440     78.5 6.08595514297485\n   Ecological_Footprint              HPI Biocapacity    GDP_per_capita\n9      2.64852226555336 62.0575517701467        1.56 20296.82150273480\n10     1.61609366019406 60.3638758082503        1.56  3153.01516775842\n11     1.90475086511154 60.1651674984682        1.56 14624.97129653470\n12     4.14251611511677 60.1046503431779        1.56 68390.71298545389\n13     1.50707276829587 58.8312130560036        1.56 11375.33118432910\n14     2.09549713846328 57.9321698535130        1.56 31458.69262552130\n\nview(HPI2019)\n\n#View map of data 'data_map', click run!\nrequire(maps)\nrequire(countrycode)\n\ndata_map <- map_data(\"world\")\nview(data_map)\n\n#Consulting the countrycode documentation for details, click run! \n?countrycode\n\n#Create a new column in data_map called 'ISO' to match the ISO column in the HPI2019 table, click run! \ndata_map$ISO = countrycode(data_map$region, origin=\"country.name\", destination = 'iso3c')\n\nWarning in countrycode_convert(sourcevar = sourcevar, origin = origin, destination = dest, : Some values were not matched unambiguously: Ascension Island, Azores, Barbuda, Bonaire, Canary Islands, Chagos Archipelago, Grenadines, Heard Island, Kosovo, Madeira Islands, Micronesia, Saba, Saint Martin, Siachen Glacier, Sint Eustatius, Virgin Islands\n\n#View updated data_map, click run! \nview(data_map)\n\n#Merge HPI2019 with data_map to create a data set which will be used to plot HPI in the world map, click run! \nmergedHPI2019 <- full_join(data_map, HPI2019, by=\"ISO\")\n\n#View merged data set, click run! \nview(mergedHPI2019)\n\n#Generate the world map chart, click run! \nggplot(mergedHPI2019, aes(x = long, y = lat, group = group, fill = HPI)) + geom_polygon() + scale_fill_viridis_c() +\n    labs(title = \"The State of Global Happiness in 2019\", subtitle = \"Based on the Happy Planet Index Score\")\n\n\n\n#Generate a barplot of the effect of GDP on HPI, click run!\nbarplot(table(mergedHPI2019$HPI, mergedHPI2019$GDP_per_capita), beside=TRUE, main= \"The Effect of GDP on HPI\", xlab= \"GDP\", ylab= \"HPI\")"
  },
  {
    "objectID": "edwardtufte.html",
    "href": "edwardtufte.html",
    "title": "Edward Tufte (2016): ‘The Future of Data Analysis’ Review",
    "section": "",
    "text": "Link to the Video- Edward Tufte (2016): The Future of Data Analysis\nWe were asked to watch the Microsoft Machine Learning & Data Science Summit 2016 Keynote Session by Dr Edward Tufte titled “The Future of Data Analysis”. The video is linked above. Below is my review and reflection on the video.\nI think that the “R” Community Lead, David Smith, had a very insightful comment. He said, “data is really more than just numbers; data is something we use to tell a story, and that we communicate that story to another person, and being able to communicate that story effectively is such an important part of what we do”. This really resonates with me, because it makes data science and data analyses so much more three-dimensional and robust. I had the misconception in how I perceive data collection and visualization as something stagnant and two-dimensional. However, this is not the case. Data visualization and analysis is meant to be something that can describe, explain, and predict phenomena that we observe in nature and society. It is such an essential skill to have as a scholar, critical thinker, and social scientist.\nAccording to Edward Tufte, data analysis is about “turning information into conclusions, analytical thinking is about assessing and evaluating relationship between information and conclusions”. The purpose of data visualization or data display is “assist reasoning about its content”. What does this mean? To me, data display is meant to help further explain or demonstrate the relationship between “information and conclusions”, such as causal mechanisms and models that attempt to describe, explain, and predict phenomena that we observe in nature and society.\nTufte asserts that the crisis in data analysis is that most published studies are false. He reiterates that the purpose of data analysis is to use empirical information to learn about the world, to describe and explain something, the find causes and effects, to advance our understanding, and to get it right; to learn and tell the truth”. However, Tufte refers to an article by John P. A. Ioannidis, which claims that upwards of 35 percent of published research findings are false due to the study power and bias. Tufte even refers to Lazer and colleagues (2014) article on the ‘Google Flu’ regarding the ‘Traps in Big Data Analysis’, i.e. the tendency of data analysts to overfit their data. The most concerning issue (to me) is that not only are original studies’ data analyses and conclusions unable to be replicated, but the replication studies are not able to be replicated, either. This is an alarming issue that questions the validity of data analyses in empirical studies.\nAccording to Tufte, human science is not rocket science; it is harder than rocket science. This is so true! Human beings and human behaviors are so dynamic and continuously changing. Therefore, data analysis within the social science field needs to be continuously advanced and developed, as well. So, what is the future of data analysis? Tufte asserts that the future of data analysis is to “take seriously the distinction between studies that are confirmatory of an idea that have not been hacked or worked over versus exploratory detective work”. He explains that this means that we must “not create findings out of the content, but out of the analysis”. We must ensure the quality of our data analysis within social science by remaining conscious, prudent, and adaptive. This way, we can produce data analysis and conclusions to the best of our abilities."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Samantha Manuel",
    "section": "",
    "text": "Projects and assignments will be posted here.\n\npar(family=\"Arial\")\nplot(iris, pch=20, cex=0.75, col=\"purple\")"
  },
  {
    "objectID": "assign01.html",
    "href": "assign01.html",
    "title": "EPPS 6356 Assignment 1",
    "section": "",
    "text": "Hoff, Anders. 2016. Differential Lattice. https://inconvergent.net/generative/differential-lattice/ (September 13, 2022).\n\n\n\n\n\nStock, Mark J. 2021. Diaspora. http://markjstock.com/#/particle/ (September 13, 2022).\n\n\n\n\n\nBrunner, Katharina. 2022. When Two Points on a Circle Form a Line. https://katharinabrunner.de/generativeart/ (September 13, 2022).\n2. Run Fall.R (on class GitHub under R.\na. Give your own colors (e.g. Spring).\nb. Export the file and post on your GitHub website.\n\n3. Write a critique on a chart in published work (book/article/news website).\n\n\n\n\n\nMcGill, Kathryn A. and Stefurak, Tres. 2021. ‘“Man Up”: Sex-Differentiated Pathways of Juvenile Delinquency through Trauma, Borderline Traits & Offense Patterns’. Juvenile and Family Court Journal 72(3): 37-65.\nThe figure, Figure 3, is titled “Graph of Interaction Effect between Sex and Borderline Traits Predicting Status Offenses”. Interaction effects plots are used to visualize how the effect of one variable varies according to the value of another variable. According to McGill and Stefurak (2021), the female participants “exhibited higher rates of borderline traits, trauma symptoms and status offenses, as hypothesized, the sex by offending interaction suggests that these symptoms are unique predictors of male’s status offending, rather than for females”. This can be seen by the positive slope of the red line for male offenders in relation to borderline traits (Efforts to avoid real or imagined abandonment, a pattern of intense and unstable relationships, distorted and unstable self-image, including feelings of dissociation, e.g. feeling cut off from oneself, feeling outside of one’s body, impulsive and often dangerous behaviors, recurring thoughts of suicidal behaviors or threats of suicide or self-harming behaviors, e.g. cutting, highly unstable and changeable mood states, chronic feelings of emptiness, anger management difficulties, interpersonal distrust) and status offenses (McGill and Stefurak 2021). In contrast, negative slope of the green line for female offenders in relation to borderline traits and status offenses indicates these symptoms are not unique predictors of female’s status offending. Although the chart does clearly and evidently show the opposite effects sex has on the relationship between borderline traits and status offending, there are some important components of this chart that are missing. For instance, the chart does not have labels on any component of the figure. For this reason, there is no reference for the interpreter to understand what the measurements are for the x and y axes. Furthermore, there is no indication as to the significance of the x and y axes units or increments. The chart also has no figure description attached to it within the article, so the reader does not have anything to refer to while interpreting the chart. For this reason, it is difficult for the reader to understand the importance or pertinence of the figure alone or independently without referring to the discussion and conclusion of the article."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Samantha Manuel",
    "section": "",
    "text": "My name is Samantha Manuel, and I am a second year PhD student in the Criminology program here at UT Dallas. I hope to help close the gap in research regarding the effects of child maltreatment on juvenile delinquency and adult criminality, and most importantly, help find potential methods to mitigate and prevent these outcomes. I recently presented my thesis, “‘I’m Still Here, I’m Still Alive’: Resilience Among Survivors of Child Maltreatment”. I presented my thesis at the Academy of Criminal Justice Sciences 59th Conference in Las Vegas, Nevada, on March 19th, 2022. This thesis illustrated how child abuse affects one’s ability to resist criminality and deviance in later adulthood. This study intended to provide a better understanding on an individual level as to why victims of childhood maltreatment choose to promote resilience and quality of life instead of criminal or antisocial behavior. By continuing with a PhD, I hope to further increase the criminological field’s understanding of why some individuals do not become criminal, and go against what is expected of them.\nMy academic interests tend to focus on juvenile delinquency and related topics. My personal belief is that the youth of society are the future, and it is imperative that scholars and policy makers alike emphasize the support and scaffolding of young community members. Once I earn my PhD, I hope to become a professor. In this position, I can help teach others the importance of research and policy development. Through my continued education here at UT Dallas, I hope to gain the skills and tools I need to become a better teacher and role model for my students. I aim to inspire the youth of these communities to dream big and to become productive members of society. In addition to teaching, professors are also expected to lead research studies. I hope to use my position to help further criminological research by applying theory to policy. In this way, I will be able to best use my position to advocate for programs and initiatives that can help improve our communities.\nIn future research, I would like to continue to investigate the causes and effects of juvenile delinquency, specifically in relation to childhood maltreatment. Furthermore, I intend to expand the recently developed concept of resiliency, which is of particular interest to me. It is inspiring to me that individuals who researchers have predicted to be deviant and criminal defy what is expected of them, and ultimately become dynamic and impactful members within their community. I also hope to close the research gap on child maltreatment, resiliency, and mental health related to minority populations, especially Asian Americans. As a future researcher, I would like to empirically assess potential policies that may positively influence these populations of individuals, and help them reduce recidivism in the long run. By obtaining my PhD degree here at UT Dallas, I will better equip myself with a vast background knowledge in my field, while also fine-tuning my teaching abilities. In this way, I hope to have as much positive influence as possible on scholars to come."
  },
  {
    "objectID": "Malinowski.html",
    "href": "Malinowski.html",
    "title": "Review of Malinowski’s Music Visualizations",
    "section": "",
    "text": "Below is the link to Stephen Malinowski’s music visualization video:\nhttps://www.youtube.com/watch?v=dFDx-L7PcrY\nThis music visualization was very interesting. Each component of the music, i.e. musical instrument, was represented by a unique color. Musical notes were connected by stings, and were denoted by circles and bars. An example of the music visualization is below.\n\n\n\n\n\nAs each note was played, the circle or bar would light up momentarily, as seen below.\n\n\n\n\n\nThis was a very interesting and inspiring visualization of musical theory!"
  },
  {
    "objectID": "assign05_6302.html",
    "href": "assign05_6302.html",
    "title": "EPPS 6302 Assignment 5",
    "section": "",
    "text": "1.Acquire data using the sample program UTDEventData1.R.\na.Collect data based on two to three countries of own choice (China, USA, and Canada)\nb.Set the time period to six months (e.g. start_date <-“20220101”; end_date = “20220630”)\nUnfortunately, this portion of the assignment could not be completed, as there were issues with the Event Data programming, and will likely not be fixed until after the semester ends. I did leave the code in this page so that it can be visualized what would have been used to complete the assignment.\n2.Register and attend Data Analytics Colloquium on 11/17/2022.\nHere is a link to the Colloquium: https://youtu.be/q-37SPXg7ko\na.Write a review on time series data and methods used in the presentation by the speaker and post on own GitHub website.\n3.Note the data and modeling methods used and do a Google scholar search on related studies.\nHere is my review of the Colloquium:\nI am going to be completely 100 percent candid: this colloquium was very challenging and difficult for me to understand. This is my very first semester intensively using R Studio and coding statistical analyses, let alone actually analyzing those statistical visualizations that I produce! Furthermore, I normally only am required to use generic regressions for my other courses; we really never really need to use other data visualization methods in order to demonstrate or display our important statistical findings. The fanciest thing I have ever done in R Studio prior to this course was an interaction effects plot, which honestly, I still have issues interpreting! All this is being said in order to give you an idea of my background knowledge of statistical methods, visualization, and interpretation skills: they are very minimal. Here is what I understood from the colloquium.\nDr. Patrick Brandt discussed multiple categories or “types” or models. These models were specific to “Statistics & Time Series for Policy Intervention & Change Identification”, which was the topic of the colloquium presentation. There were four types of models or visualizations that Dr. Brandt described: Type 0 (Basic Time Series), Type 1 (Binary Segmentation), Type 2 (Regularization and Fused Lasso), and Type 3 (Bayesian methods). Below are further descriptions of each method of these data visualizations:\nModel Type 0: Basic Time Series Model\n\nSimple model where the moment where the intervention occurs is identifiable.\nEasy for estimations.\nModels allow for many differences; Type 0 does not necessarily show distinct difference between multiple factors.\nExample used: Gas prices and seat belts; Salmonella in chicken breeding\n\nModel Type 1: Binary Segmentation\n\nThis model is commonly used for trends that are more complex, deterministic, or stochastic.\nWhat is stochastic? According to the Oxford Dictionary, “stochastic” means that the data/values are “randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely”.\nExample used: US Industrial Revolution and COVID.\n\nModel Type 2: L1/L0 Regularization and Fused Lasso\n\nThis type of model treats the issue by identifying a correct set of covariates from the possible sets of interventions presented by the data.\nThere are different ways to identify these covariates:\n\nSearch for each of the change-points individually.\nAssessing the probability of a change-point.\nFused Lasso Model: univariate vs. multivariate analyses\n(Safikhani et al. 2022).\n\n\nModel Type 3: Bayesian Methods\n\nThis method was mentioned briefly, but not discussed in detail.\nHere is a definition of Bayesian models from a quick Google search: “A Bayesian model is a statistical model where you use probability to represent all uncertainty within the model, both the uncertainty regarding the output but also the uncertainty regarding the input (aka parameters) to the model.”\n\n\n# Event Data Replication\n\n# Clearing the environment\nrm(list=ls())\n\n# Install the packages and load the libraries.\nlibrary(devtools)\n\nLoading required package: usethis\n\nlibrary(remotes)\n\n\nAttaching package: 'remotes'\n\n\nThe following objects are masked from 'package:devtools':\n\n    dev_package_deps, install_bioc, install_bitbucket, install_cran,\n    install_deps, install_dev, install_git, install_github,\n    install_gitlab, install_local, install_svn, install_url,\n    install_version, update_packages\n\n\nThe following object is masked from 'package:usethis':\n\n    git_credentials\n\ndevtools::install_github(\"KateHyoung/UTDEventData\", build_vignettes=TRUE)\n\nSkipping install of 'UTDEventData' from a github remote, the SHA1 (2ddb9364) has not changed since last install.\n  Use `force = TRUE` to force installation\n\nlibrary(UTDEventData)\n\n# Creating the variables to pull from the server\nk <- \"La7UsSUjrPmIZ3a7qqgbgVXp1wsLiWgN\"\ncountries <- c(\"CHN\",\"USA\",\"CAN\")\nstart_date <- \"20220101\"\nend_date <- \"20220630\"\ntable <- \"phoenix_rt\"\n\n# Below is the code that currently cannot be ran due to outside circumstances. \n# EventData <- pullData(k, table, countries, start_date, end_date, citation = FALSE)\n# View(EventData)\n\n\n# Data Analytics Colloquium Replication of Model Type 0: Times Series Model\n\nlapply(c(\"quantmod\", \"tidyverse\",\"TSstudio\"), require, character.only = TRUE)\n\nLoading required package: quantmod\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nLoading required package: tidyverse\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\nLoading required package: TSstudio\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\nlibrary(TSstudio)\nquantmod::getSymbols(\"TSLA\", src=\"yahoo\")\n\n[1] \"TSLA\"\n\nts_plot(TSLA$TSLA.Adjusted, \n        title = \"Tesla Stock prices\",\n        Ytitle = \"\")"
  },
  {
    "objectID": "assign04_6302.html",
    "href": "assign04_6302.html",
    "title": "EPPS 6302 Assignment 4",
    "section": "",
    "text": "b. US presidential inaugural speeches\ni. Any similarities and differences over time and among presidents?\nThe presidents used similar words in their speeches. Many of the common words used amongst the previous and current presidents are America-centric, and relate to “America” and American values. Below are some charts showcasing these similarities and differences. The first chart is a word cloud of the most common words used by former Presidents George Bush, Barrack Obama, and Donald Trump. It can be seen that all three president used very similar wording; the largest words, i.e. the most frequently used words, were related the America or the US, or the country as a whole.\n\nAs it can be seen in the chart below, the four most recent presidents including the current president, Joe Biden, still use similar phrasing. “America”, “nation”, and “people/citizens” all topped the four presidents’ most commonly used words. The ten most common words used all still related to America and American values, such as “freedom” and “liberty”.\n\nii. Analyze positions of different presidents.\nThe chart below depicts the relative frequency of the word “American” used by the ten most recent presidents of the United States. As it can be seen, the frequency of this word usage is very sporadic. The one most notable feature of the chart however, is how much more frequent Donald Trump used the word “American” in comparison to the other presidents.\n\nc. What is Wordfish?\nHere is an excerpt from Quanteda itself (Link to Quanteda Website) describing what Wordfish is:\n“Wordfish is a Poisson scaling model of one-dimensional document positions (Slapin and Proksch 2008). Wordfish also allows for scaling documents, but compared to Wordscores reference scores/texts are not required. Wordfish is an unsupervised one-dimensional text scaling method, meaning that it estimates the positions of documents solely based on the observed word frequencies.” (Quanteda)\nHere is another description of what Wordfish is from Slapin and Proksch (2008), the developers of Wordfish:\n“Recent advances in computational content analysis have provided scholars promising new ways for estimating party positions. However, existing text-based methods face challenges in producing valid and reliable time-series data. This article proposes a scaling algorithm called WORDFISH to estimate policy positions based on word frequencies in texts. The technique allows researchers to locate parties in one or multiple elections.” (Slapin and Proksch 2008)\nHere is the link to their peer-reviewed article for more information: https://doi.org/10.1111/j.1540-5907.2008.00338.x\n\n\n# Sample program for using quanteda for text modeling and analysis\n# Use vignette(\"auth\", package = \"rtweet\") for authentication\n# Documentation: vignette(\"quickstart\", package = \"quanteda\")\n# Website: https://quanteda.io/\n\nlibrary(quanteda)\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"mMatrix\"; definition not updated\n\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"replValueSp\"; definition not updated\n\n\nPackage version: 3.2.3\nUnicode version: 14.0\nICU version: 70.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(readr)\nlibrary(ggplot2)\n\n# Twitter data about President Biden and Xi summit in November 2021\n# Do some background search/study on the event\n\nsummit <- read_csv(\"https://raw.githubusercontent.com/datageneration/datamethods/master/textanalytics/summit_11162021.csv\")\n\nRows: 14520 Columns: 90\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (50): screen_name, text, source, reply_to_screen_name, hashtags, symbol...\ndbl  (26): user_id, status_id, display_text_width, reply_to_status_id, reply...\nlgl  (10): is_quote, is_retweet, quote_count, reply_count, ext_media_type, q...\ndttm  (4): created_at, quoted_created_at, retweet_created_at, account_create...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(summit)\n\n# A tibble: 6 × 90\n  user_id status_id created_at          screen_name    text              source \n    <dbl>     <dbl> <dttm>              <chr>          <chr>             <chr>  \n1 1.38e18   1.46e18 2021-11-16 20:10:23 DSJ78992721    \"Breaking News: … Twitte…\n2 2.60e 8   1.46e18 2021-11-16 20:10:17 bradhooperarch \"https://t.co/rK… Twitte…\n3 3.00e 9   1.46e18 2021-11-16 20:10:10 scarecrow1113  \"[Recap] Biden u… Twitte…\n4 3.00e 9   1.46e18 2021-11-15 19:24:04 scarecrow1113  \"U.S. President … Twitte…\n5 1.36e18   1.46e18 2021-11-16 06:22:29 Internl_Leaks  \"#BREAKING Biden… Twitte…\n6 1.36e18   1.46e18 2021-11-16 20:09:36 Internl_Leaks  \"#BREAKING Biden… Twitte…\n# … with 84 more variables: display_text_width <dbl>, reply_to_status_id <dbl>,\n#   reply_to_user_id <dbl>, reply_to_screen_name <chr>, is_quote <lgl>,\n#   is_retweet <lgl>, favorite_count <dbl>, retweet_count <dbl>,\n#   quote_count <lgl>, reply_count <lgl>, hashtags <chr>, symbols <chr>,\n#   urls_url <chr>, urls_t.co <chr>, urls_expanded_url <chr>, media_url <chr>,\n#   media_t.co <chr>, media_expanded_url <chr>, media_type <chr>,\n#   ext_media_url <chr>, ext_media_t.co <chr>, ext_media_expanded_url <chr>, …\n\nsum_twt = summit$text\ntoks = tokens(sum_twt)\nsumtwtdfm <- dfm(toks)\n\n# Latent Semantic Analysis\nsum_lsa <- textmodel_lsa(sumtwtdfm)\nsummary(sum_lsa)\n\n                Length    Class     Mode   \nsk                     10 -none-    numeric\ndocs               145200 -none-    numeric\nfeatures           160020 -none-    numeric\nmatrix_low_rank 232349040 -none-    numeric\ndata            232349040 dgCMatrix S4     \n\ntweet_dfm <- tokens(sum_twt, remove_punct = TRUE) %>%\n  dfm()\nhead(tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 15,941 features (99.89% sparse) and 0 docvars.\n       features\ndocs    breaking news us president biden amp communist china leader xi\n  text1        1    1  1         1     1   1         1     2      1  1\n  text2        0    0  0         0     0   0         0     0      0  0\n  text3        0    0  0         0     1   0         0     0      0  1\n  text4        0    0  0         1     1   0         0     0      0  1\n  text5        0    0  0         0     1   0         0     0      0  1\n  text6        0    0  0         0     1   0         0     0      0  1\n[ reached max_nfeat ... 15,931 more features ]\n\ntag_dfm <- dfm_select(tweet_dfm, pattern = \"#*\")\ntoptag <- names(topfeatures(tag_dfm, 50))\nhead(toptag, 10)\n\n [1] \"#china\"          \"#biden\"          \"#xijinping\"      \"#joebiden\"      \n [5] \"#america\"        \"#americans\"      \"#coronavirus\"    \"#fentanyl\"      \n [9] \"#xi\"             \"#uyghurgenocide\"\n\nlibrary(\"quanteda.textplots\")\ntag_fcm <- fcm(tag_dfm)\nhead(tag_fcm)\n\nFeature co-occurrence matrix of: 6 by 685 features.\n               features\nfeatures        #breaking #breakingnews #biden #china #usa #pray4america\n  #breaking             0             4      4      5    5             0\n  #breakingnews         0             0      4      5    4             0\n  #biden                0             0      0    415   44             0\n  #china                0             0      0      8   76             0\n  #usa                  0             0      0      0    6             0\n  #pray4america         0             0      0      0    0             0\n               features\nfeatures        #joebiden #xijinping #america #americans\n  #breaking             0          0        0          0\n  #breakingnews         0          0        0          0\n  #biden              299        366      301        295\n  #china              339        433      308        295\n  #usa                 12         14        0          0\n  #pray4america         0          0        0          0\n[ reached max_nfeat ... 675 more features ]\n\ntopgat_fcm <- fcm_select(tag_fcm, pattern = toptag)\ntextplot_network(topgat_fcm, min_freq = 50, edge_alpha = 0.8, edge_size = 5)\n\n\n\nuser_dfm <- dfm_select(tweet_dfm, pattern = \"@*\")\ntopuser <- names(topfeatures(user_dfm, 50))\nhead(topuser, 20)\n\n [1] \"@potus\"           \"@joebiden\"        \"@politico\"        \"@eneskanter\"     \n [5] \"@jendeben\"        \"@nwadhams\"        \"@nba\"             \"@washwizards\"    \n [9] \"@pelicansnba\"     \"@capitalonearena\" \"@kevinliptakcnn\"  \"@foxbusiness\"    \n[13] \"@morningsmaria\"   \"@scmpnews\"        \"@uyghur_american\" \"@nytimes\"        \n[17] \"@petermartin_pcm\" \"@nahaltoosi\"      \"@phelimkine\"      \"@kaylatausche\"   \n\nuser_fcm <- fcm(user_dfm)\nhead(user_fcm, 20)\n\nFeature co-occurrence matrix of: 20 by 741 features.\n                 features\nfeatures          @youtube @bfmtv @cnn @lauhaim @barackobama @joebiden\n  @youtube               0      0    0        0            0         0\n  @bfmtv                 0      0    1        1            1         1\n  @cnn                   0      0    0        1            1         1\n  @lauhaim               0      0    0        0            1         1\n  @barackobama           0      0    0        0            0         1\n  @joebiden              0      0    0        0            0         3\n  @kamalaharris          0      0    0        0            0         0\n  @hillaryclinton        0      0    0        0            0         0\n  @billclinton           0      0    0        0            0         0\n  @cbsnews               0      0    0        0            0         0\n                 features\nfeatures          @kamalaharris @hillaryclinton @billclinton @cbsnews\n  @youtube                    0               0            0        0\n  @bfmtv                      1               1            1        1\n  @cnn                        1               1            1        1\n  @lauhaim                    1               1            1        1\n  @barackobama                1               1            1        1\n  @joebiden                   1               1            1        1\n  @kamalaharris               0               1            1        1\n  @hillaryclinton             0               0            1        1\n  @billclinton                0               0            0        1\n  @cbsnews                    0               0            0        0\n[ reached max_feat ... 10 more features, reached max_nfeat ... 731 more features ]\n\nuser_fcm <- fcm_select(user_fcm, pattern = topuser)\ntextplot_network(user_fcm, min_freq = 20, edge_color = \"firebrick\", edge_alpha = 0.8, edge_size = 5)\n\n\n\n# Wordcloud\n# based on US presidential inaugural address texts, and metadata (for the corpus), from 1789 to present.\ndfm_inaug <- corpus_subset(data_corpus_inaugural, Year <= 1826) %>% \n  dfm(remove = stopwords('english'), remove_punct = TRUE) %>%\n  dfm_trim(min_termfreq = 10, verbose = FALSE)\n\nWarning: 'dfm.corpus()' is deprecated. Use 'tokens()' first.\n\n\nWarning: '...' should not be used for tokens() arguments; use 'tokens()' first.\n\n\nWarning: 'remove' is deprecated; use dfm_remove() instead\n\nset.seed(100)\ntextplot_wordcloud(dfm_inaug)\n\n\n\ninaug_speech = data_corpus_inaugural\n\ncorpus_subset(data_corpus_inaugural, \n              President %in% c(\"Trump\", \"Obama\", \"Bush\")) %>%\n  tokens(remove_punct = TRUE) %>%\n  tokens_remove(stopwords(\"english\")) %>%\n  dfm() %>%\n  dfm_group(groups = President) %>%\n  dfm_trim(min_termfreq = 5, verbose = FALSE) %>%\n  textplot_wordcloud(comparison = TRUE)\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nthroughout could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud_comparison(x, min_size, max_size, min_count, max_words, :\nchildren could not be fit on page. It will not be plotted.\n\n\n\n\ntextplot_wordcloud(dfm_inaug, min_count = 10,\n                   color = c('red', 'pink', 'green', 'purple', 'orange', 'blue'))\n\n\n\ndata_corpus_inaugural_subset <- \n  corpus_subset(data_corpus_inaugural, Year > 1949)\nkwic(tokens(data_corpus_inaugural_subset), pattern = \"american\") %>%\n  textplot_xray()\n\n\n\ntextplot_xray(\n  kwic(data_corpus_inaugural_subset, pattern = \"american\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"people\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"communist\")\n)\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\n\n\n\ntheme_set(theme_bw())\ng <- textplot_xray(\n  kwic(data_corpus_inaugural_subset, pattern = \"american\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"people\"),\n  kwic(data_corpus_inaugural_subset, pattern = \"communist\")\n)\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\nWarning: 'kwic.corpus()' is deprecated. Use 'tokens()' first.\n\ng + aes(color = keyword) + \n  scale_color_manual(values = c(\"blue\", \"red\", \"green\")) +\n  theme(legend.position = \"none\")\n\n\n\nlibrary(\"quanteda.textstats\")\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"mMatrix\"; definition not updated\n\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"replValueSp\"; definition not updated\n\nfeatures_dfm_inaug <- textstat_frequency(dfm_inaug, n = 100)\n\n# Sort by reverse frequency order\nfeatures_dfm_inaug$feature <- with(features_dfm_inaug, reorder(feature, -frequency))\n\nggplot(features_dfm_inaug, aes(x = feature, y = frequency)) +\n  geom_point() + \n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n# Get frequency grouped by president\nfreq_grouped <- textstat_frequency(dfm(tokens(data_corpus_inaugural_subset)), \n                                   groups = data_corpus_inaugural_subset$President)\n\n# Filter the term \"american\"\nfreq_american <- subset(freq_grouped, freq_grouped$feature %in% \"american\")  \n\nggplot(freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 14), breaks = c(seq(0, 14, 2))) +\n  xlab(NULL) + \n  ylab(\"Frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\ndfm_rel_freq <- dfm_weight(dfm(tokens(data_corpus_inaugural_subset)), scheme = \"prop\") * 100\nhead(dfm_rel_freq)\n\nDocument-feature matrix of: 6 documents, 4,346 features (85.57% sparse) and 4 docvars.\n                 features\ndocs                      my    friends        ,    before          i\n  1953-Eisenhower 0.14582574 0.14582574 4.593511 0.1822822 0.10936930\n  1957-Eisenhower 0.20975354 0.10487677 6.345045 0.1573152 0.05243838\n  1961-Kennedy    0.19467878 0.06489293 5.451006 0.1297859 0.32446463\n  1965-Johnson    0.17543860 0.05847953 5.555556 0.2339181 0.87719298\n  1969-Nixon      0.28973510 0          5.546358 0.1241722 0.86920530\n  1973-Nixon      0.05012531 0.05012531 4.812030 0.2005013 0.60150376\n                 features\ndocs                   begin      the expression       of     those\n  1953-Eisenhower 0.03645643 6.234050 0.03645643 5.176814 0.1458257\n  1957-Eisenhower 0          5.977976 0          5.034085 0.1573152\n  1961-Kennedy    0.19467878 5.580792 0          4.218040 0.4542505\n  1965-Johnson    0          4.502924 0          3.333333 0.1754386\n  1969-Nixon      0          5.629139 0          3.890728 0.4552980\n  1973-Nixon      0          4.160401 0          3.408521 0.3007519\n[ reached max_nfeat ... 4,336 more features ]\n\nrel_freq <- textstat_frequency(dfm_rel_freq, groups = dfm_rel_freq$President)\n\n# Filter the term \"american\"\nrel_freq_american <- subset(rel_freq, feature %in% \"american\")  \n\nggplot(rel_freq_american, aes(x = group, y = frequency)) +\n  geom_point() + \n  scale_y_continuous(limits = c(0, 0.7), breaks = c(seq(0, 0.7, 0.1))) +\n  xlab(NULL) + \n  ylab(\"Relative frequency\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\ndfm_weight_pres <- data_corpus_inaugural %>%\n  corpus_subset(Year > 2000) %>%\n  tokens(remove_punct = TRUE) %>%\n  tokens_remove(stopwords(\"english\")) %>%\n  dfm() %>%\n  dfm_weight(scheme = \"prop\")\n\n# Calculate relative frequency by president\nfreq_weight <- textstat_frequency(dfm_weight_pres, n = 10, \n                                  groups = dfm_weight_pres$President)\n\nggplot(data = freq_weight, aes(x = nrow(freq_weight):1, y = frequency)) +\n  geom_point() +\n  facet_wrap(~ group, scales = \"free\") +\n  coord_flip() +\n  scale_x_continuous(breaks = nrow(freq_weight):1,\n                     labels = freq_weight$feature) +\n  labs(x = NULL, y = \"Relative frequency\")\n\n\n\n# Only select speeches by Obama and Trump\npres_corpus <- corpus_subset(data_corpus_inaugural, \n                             President %in% c(\"Obama\", \"Trump\"))\n\n# Create a dfm grouped by president\npres_dfm <- tokens(pres_corpus, remove_punct = TRUE) %>%\n  tokens_remove(stopwords(\"english\")) %>%\n  tokens_group(groups = President) %>%\n  dfm()\n\n# Calculate keyness and determine Trump as target group\nresult_keyness <- textstat_keyness(pres_dfm, target = \"Trump\")\n\n# Plot estimated word keyness\ntextplot_keyness(result_keyness) \n\n\n\n# Plot without the reference text (in this case Obama)\ntextplot_keyness(result_keyness, show_reference = FALSE)\n\n\n\nlibrary(\"quanteda.textmodels\")\n\n# Transform corpus to dfm\ndata(data_corpus_irishbudget2010, package = \"quanteda.textmodels\")\nie_dfm <- dfm(tokens(data_corpus_irishbudget2010))\n\n# Set reference scores\nrefscores <- c(rep(NA, 4), 1, -1, rep(NA, 8))\n\n# Predict Wordscores model\nws <- textmodel_wordscores(ie_dfm, y = refscores, smooth = 1)\n\n# Plot estimated word positions (highlight words and print them in red)\ntextplot_scale1d(ws,\n                 highlighted = c(\"minister\", \"have\", \"our\", \"budget\"), \n                 highlighted_color = \"red\")\n\n\n\n# Get predictions\npred <- predict(ws, se.fit = TRUE)\n\n# Plot estimated document positions and group by \"party\" variable\ntextplot_scale1d(pred, margin = \"documents\",\n                 groups = docvars(data_corpus_irishbudget2010, \"party\"))\n\n\n\n# Plot estimated document positions using the LBG transformation and group by \"party\" variable\n\npred_lbg <- predict(ws, se.fit = TRUE, rescaling = \"lbg\")\n\ntextplot_scale1d(pred_lbg, margin = \"documents\",\n                 groups = docvars(data_corpus_irishbudget2010, \"party\"))\n\n\n\n# Estimate Wordfish model\nlibrary(\"quanteda.textmodels\")\nwf <- textmodel_wordfish(dfm(tokens(data_corpus_irishbudget2010)), dir = c(6, 5))\n\n# Plot estimated word positions\ntextplot_scale1d(wf, margin = \"features\", \n                 highlighted = c(\"government\", \"global\", \"children\", \n                                 \"bank\", \"economy\", \"the\", \"citizenship\",\n                                 \"productivity\", \"deficit\"), \n                 highlighted_color = \"red\")\n\n\n\n# Plot estimated document positions\ntextplot_scale1d(wf, groups = data_corpus_irishbudget2010$party)\n\n\n\n# Transform corpus to dfm\nie_dfm <- dfm(tokens(data_corpus_irishbudget2010))\n\n# Run correspondence analysis on dfm\nca <- textmodel_ca(ie_dfm)\n\n# Plot estimated positions and group by party\ntextplot_scale1d(ca, margin = \"documents\",\n                 groups = docvars(data_corpus_irishbudget2010, \"party\"))"
  },
  {
    "objectID": "assign09.html",
    "href": "assign09.html",
    "title": "EPPS 6356 Assignment 9",
    "section": "",
    "text": "Collect your own time series data and import into R (e.g. you can use quantmod to collect stock data)\n\nFigure 1: Time Series Plot of Clover Health Insurance Stocks.\n\nFigure 2: Candlestick Time Series Plot of Clover Health Insurance Stocks.\nExamine class of time series object and variables:\ni. Trend\nTrend refers to the general movement of the data over time, such as in the example time series plots. The trend of the CLOV data had a fairly stable neutral trend until July 2021, which has since been on a general downwards trend.\nii. Stationarity\nStationarity is demonstrated by a flat looking series, without trend, constant variance over time, a constant autocorrelation structure over time and no periodic fluctuations (seasonality). On the other hand, nonstationarity is the status of a time series whose statistical properties are changing through time. The CLOV data generally is nonstationary, i.e., the CLOV data does have a general negative trend.\niii. pdq\nA nonseasonal ARIMA model is classified as an “ARIMA(p,d,q)” model, where: p is the number of autoregressive terms, d is the number of nonseasonal differences needed for stationarity, and q is the number of lagged forecast errors in the prediction equation. The pdq of the CLOV data generally, at least since July 2021, could be generally predicted due to general negative trend and nonstationarity.\n\n\n# Plotting time series data using TSstudio\n\nlapply(c(\"quantmod\", \"tidyverse\",\"TSstudio\"), require, character.only = TRUE)\n\nLoading required package: quantmod\n\n\nLoading required package: xts\n\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: TTR\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nLoading required package: tidyverse\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   0.3.4 \n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\nLoading required package: TSstudio\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\nlibrary(TSstudio)\nquantmod::getSymbols(\"CLOV\", src=\"yahoo\")\n\n[1] \"CLOV\"\n\nts_plot(CLOV$CLOV.Adjusted, \n        title = \"Clover Health Insurance Stock prices\",\n        Ytitle = \"\")\n\n\n\n\nclass(CLOV)\n\n[1] \"xts\" \"zoo\"\n\n# Plotting time series data using dygraph\nlapply(c(\"quantmod\", \"tidyverse\",\"dygraphs\"), require, character.only = TRUE)\n\nLoading required package: dygraphs\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\nlibrary(dygraphs)\npar(family=\"Palatino\")\nquantmod::getSymbols(\"CLOV\", src=\"yahoo\")\n\n[1] \"CLOV\"\n\nclass(CLOV)\n\n[1] \"xts\" \"zoo\"\n\nm = tail(CLOV, n=30)\nm =m[,1:(ncol(m)-2)] # drop last two columns \nnames(m)<-c('Open', 'High', 'Low', 'Close') # rename columns for plotting\npath <- getwd()\nsetwd(\"~/Documents/Fall 2022/EPPS 6356/samantha-manuel.github.io\") # place dygraph.css into the same directory\ndygraph(m, main = \"Clover Health Insurance Stock Prices (Candlestick Chart)\")  |>  \n  dyCandlestickGroup(c('Open', 'High', 'Low', 'Close')) |> \n  dyCandlestick()  |> \n  dyLegend(show = \"always\", hideOnMouseOut = T) |> \n  dyCSS(\"dygraph.css\")"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "googleflu_wickham.html",
    "href": "googleflu_wickham.html",
    "title": "‘Google Flu’ and Hadley Wickham’s EMBL Review",
    "section": "",
    "text": "Part 1: “The Parable of Google Flu: Traps in Big Data Analysis”\n\n\n\n\n\nLazer, David, Kennedy, Ryan, King, Gary, and Vespignani, Alessandro, 2014. The Parable of Google Flu: Traps in Big Data Analysis. *Science*, [online\\] 343(6176), pp.1203-1205. Available at: https://www.science.org/doi/full/10.1126/science.1248506 [Accessed 27 September 2022].\nCritique on:\ni.Big data analytics pitfall\nAccording to the authors (2014), ‘Big data hubris’ is the “often implicit assumption that big data are a substitute for, rather than a supplement to, traditional data collection and analysis”. This relates to the issue that quantity of data does not mean quality. Big data analytics fall to the concerns of measurement and construct validity issues, as well as reliability and dependency difficulties. This is essentially referring to the instruments used to measure the observations and data are not the best fit for producing the most valid and reliable data analysis and subsequent conclusion. Furthermore, Google heavily relies on algorithms to estimate future flu trends. This can be seen in the figure below. GFT overestimates the prevalence of flu during flu seasons, such as the 2012-2013 season seen in the figure. This is viewed as Google’s most common error, and as resulted in a panic instigated by the media (Lazer et al. 2014).\n\n\n\n\n\nii.Overfitting and overparameterization.\nAccording to Lazer and colleagues (2014), the Google Flu Trends (GFT) of 2013 have been “persistently overestimating flu prevalence for a much longer time” than just nine years ago. This is primarily due to errors associated with not being randomly distributed; this has been an issue with Google’s flu data analysis since even the 2011-2012 flu season (Lazer et al. 2014). Errors included using “last week’s errors [to] predict this week’s errors (temporal autocorrelation), and the direction and magnitude of error varies with the time of year (seasonality)” (Lazer et al. 2014). In other words, the GFT avoids the traditional use of statistical methods by overlooking pertinent information and data. This refers back to Google’s use of algorithms and computer programs to estimate flu trends instead of depending on actual data collection. The authors (2014) conclude that although big data offer “enormous possibilities for understanding human interactions at a societal scale”, it is also important to consider “small data”, as it provides supplemental perspective to data analyses.\nPart 2: Hadley Wickham’s (2019) presentation of “Data Visualization and Data Science”\n\n\n\n\n\nLink to the Video- Hadley Wickham (2019): Data Visualization and Data Science\nName the technologies/techniques Wickham introduced. What are his main points? Summarize and comment.\nAfter watching this video, I was thoroughly impressed with the advancement of R Studio. Data visualization on R Studio would be so much more difficult and convoluted without the creation of the tidyverse package. This we have Hadley Wickham to thank for. Wickham is the creator of ggplot, ggplot2, and dplyr, tidyr, and purrr functions, all of which make up the package “tidyverse”. Below is a model that Wickham presented to visualize how different functions/packages are used in R Studio:\n\n\n\n\n\nI really appreciated Wickham’s relationship of his lecture to the infamous data set “gapminder”, which is a data set describing how countries’ incomes (GDP per capita), life expectancies, and populations changed over time. They also grouped the countries by region: the Americas, Europe, Asia, and Africa. Below is the code that he used to describe the components of ggplot2 code:\n\nWickham emphasizes the importance of learning the language of code, so that it will become easier to construct data visualization code in R Studio. He asserts that like linguistic languages, coding is also a language that needs to be deconstructed to become fluent. The code above therefore can be read as if it says, “Read the ‘gapminder’ dataset by filtering for just data from the year 2015, and create a new variable called ‘gapminder15’”.\nHe continues to discuss the power of ‘orthogonal components’. According to Wickham (2019), orthogonal components refer to the orthogonality of a data set, or the separability of different features within a system. Wickharm asserts that we must look at data as a function, and therefore like a function, data has distinct components or variables within it. Orthogonality therefore highlights specific variables of interest or pertinence to visualize and analyze. In the ‘gapminder’ set, Wickham highlights the concept of orthogonality by generating a plot with income/GDP per capita (on the x axis) and life expectancy (on the y axis) by country and region using the tidyverse package. Below is the generated chart.\n\n\n\n\n\nTo conclude, Wickham discusses the importance and the power of code. He highlights three main advantages to code: code is text, readable, and reproducible. Because code is text, it is able to be copied and pasted. Code is also a language, which means that other people can read it as well and possibly critique and even improve your code. Finally, code is reproducible, and allows you to rerun the code with updated or changed data easily and efficiently.\nAll of these points that Wickham makes further emphasize how helpful coding is to visualize and subsequently analyze data, especially with the help of developed code functions and packages. For this, we really have Wickham to thank!"
  },
  {
    "objectID": "assign02_6302.html",
    "href": "assign02_6302.html",
    "title": "EPPS 6302 Assignment 2",
    "section": "",
    "text": "# Data Method: Text mining\n# File: textmining1.R\n# Theme: Download text data from web and create wordcloud\n\n# Install the easypackages package \nlibrary(tm)\n\nLoading required package: NLP\n\nlibrary(quanteda)\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"mMatrix\"; definition not updated\n\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"replValueSp\"; definition not updated\n\n\nPackage version: 3.2.3\nUnicode version: 14.0\nICU version: 70.1\n\n\nParallel computing: 8 of 8 threads used.\n\n\nSee https://quanteda.io for tutorials and examples.\n\n\n\nAttaching package: 'quanteda'\n\n\nThe following object is masked from 'package:tm':\n\n    stopwords\n\n\nThe following objects are masked from 'package:NLP':\n\n    meta, meta<-\n\nlibrary(easypackages)\n\n# Load multiple packages using easypackage function \"packages\"\npackages(\"XML\",\"wordcloud\",\"RColorBrewer\",\"NLP\", prompt = T)\n\nLoading required package: XML\n\n\nLoading required package: wordcloud\n\n\nLoading required package: RColorBrewer\n\n\nAll packages loaded successfully\n\n# Download text data from website\n# Run the program on Winston Churchill's Finest Hour speech\nchurchLocation <-URLencode(\"http://www.historyplace.com/speeches/churchill-hour.htm\")\n\n# use htmlTreeParse function to read and parse paragraphs\ndoc.html<- htmlTreeParse(churchLocation, useInternal=TRUE)\nchurch <- unlist(xpathApply(doc.html, '//p', xmlValue))\n\nhead(church, 3)\n\n[1] \"\"                                                                                                                                                                                                                                                                                                        \n[2] \"\"                                                                                                                                                                                                                                                                                                        \n[3] \"\\n        At 5:30 a.m. on May 10, 1940, Nazi Germany began a massive attack against\\n        Holland, Belgium, Luxembourg, and France. Defending those countries were\\n        soldiers of the British Expeditionary Force  along with the French, Belgian,\\n        and Dutch (Allied) armies. \\n      \"\n\n# Vectorize Churchill\nwords.vec <- VectorSource(church)\n\n# Check the class of words.vec\nclass(words.vec)\n\n[1] \"VectorSource\" \"SimpleSource\" \"Source\"      \n\n# Create Corpus object for preprocessing\nwords.corpus <- Corpus(words.vec)\ninspect(words.corpus)\n\n<<SimpleCorpus>>\nMetadata:  corpus specific: 1, document level (indexed): 0\nContent:  documents: 38\n\n [1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n [2]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n [3] \\n        At 5:30 a.m. on May 10, 1940, Nazi Germany began a massive attack against\\n        Holland, Belgium, Luxembourg, and France. Defending those countries were\\n        soldiers of the British Expeditionary Force  along with the French, Belgian,\\n        and Dutch (Allied) armies. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n [4]   The Germans relied on an aggressive battle plan,\\n        utilizing modern communications such as radio to direct troops in the field. The Allies, for their part, assumed a defensive posture, just as they had done at the start of World War I, and in many cases  still relied\\n        on hand-delivered messages.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n [5] As a result, the German Blitzkrieg\\n        (lightning attack)  caught the Allies off-guard.  German Panzer tanks staged a surprise attack through the 'impassable' Ardennes  Forest then turned northward\\n        and soon surrounded the bulk of the Allied armies in Belgium. The \"Miracle at Dunkirk\" occurred\\n        next as 338,000 British and French soldiers were hurriedly evacuated from the coastline\\n        by  Royal Navy ships and a flotilla\\n        of  civilian boats of every shape and size.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n [6] After just a few weeks of battle, Hitler's armies had conquered Holland, Luxembourg and Belgium. Paris fell on June 14th. Three days later, the French requested an armistice.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n [7] The following day, June 18th, British Prime Minister Winston Churchill\\n        spoke to the House of Commons about the disastrous turn of events in Europe amid the stark realization\\n        that Britain now stood alone against the seemingly unstoppable might of Hitler's military machine.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n [8]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n [9] I spoke the other day of the colossal military disaster which occurred\\nwhen the French High Command failed to withdraw the northern Armies from\\nBelgium at the moment when they knew that the French front was decisively\\nbroken at Sedan and on the Meuse. This delay entailed the loss of fifteen\\nor sixteen French divisions and threw out of action for the critical period\\nthe whole of the British Expeditionary Force. Our Army and 120,000 French\\ntroops were indeed rescued by the British Navy from Dunkirk but only with\\nthe loss of their cannon, vehicles and modern equipment. This loss inevitably\\ntook some weeks to repair, and in the first two of those weeks the battle\\nin France has been lost. When we consider the heroic resistance made by\\nthe French Army against heavy odds in this battle, the enormous losses\\ninflicted upon the enemy and the evident exhaustion of the enemy, it may\\nwell be the thought that these 25 divisions of the best-trained and best-equipped\\ntroops might have turned the scale. However, General Weygand had to fight\\nwithout them. Only three British divisions or their equivalent were able\\nto stand in the line with their French comrades. They have suffered severely,\\nbut they have fought well. We sent every man we could to France as fast\\nas we could re-equip and transport their formations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n[10] I am not reciting these facts for the purpose of recrimination. That\\nI judge to be utterly futile and even harmful. We cannot afford it. I recite\\nthem in order to explain why it was we did not have, as we could have had,\\nbetween twelve and fourteen British divisions fighting in the line in this\\ngreat battle instead of only three. Now I put all this aside. I put it\\non the shelf, from which the historians, when they have time, will select\\ntheir documents to tell their stories. We have to think of the future and\\nnot of the past. This also applies in a small way to our own affairs at\\nhome. There are many who would hold an inquest in the House of Commons\\non the conduct of the Governments--and of Parliaments, for they are in\\nit, too--during the years which led up to this catastrophe. They seek to\\nindict those who were responsible for the guidance of our affairs. This\\nalso would be a foolish and pernicious process. There are too many in it.\\nLet each man search his conscience and search his speeches. I frequently\\nsearch mine.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n[11] Of this I am quite sure, that if we open a quarrel between the past\\nand the present, we shall find that we have lost the future. Therefore,\\nI cannot accept the drawing of any distinctions between members of the\\npresent Government. It was formed at a moment of crisis in order to unite\\nall the Parties and all sections of opinion. It has received the almost\\nunanimous support of both Houses of Parliament. Its members are going to\\nstand together, and, subject to the authority of the House of Commons,\\nwe are going to govern the country and fight the war. It is absolutely\\nnecessary at a time like this that every Minister who tries each day to\\ndo his duty shall be respected; and their subordinates must know that their\\nchiefs are not threatened men, men who are here today and gone tomorrow,\\nbut that their directions must be punctually and faithfully obeyed. Without\\nthis concentrated power we cannot face what lies before us. I should not\\nthink it would be very advantageous for the House to prolong this debate\\nthis afternoon under conditions of public stress. Many facts are not clear\\nthat will be clear in a short time. We are to have a secret session on\\nThursday, and I should think that would be a better opportunity for the\\nmany earnest expressions of opinion which members will desire to make and\\nfor the House to discuss vital matters without having everything read the\\nnext morning by our dangerous foes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[12] The disastrous military events which have happened during the past\\nfortnight have not come to me with any sense of surprise. Indeed, I indicated\\na fortnight ago as clearly as I could to the House that the worst possibilities\\nwere open; and I made it perfectly clear then that whatever happened in\\nFrance would make no difference to the resolve of Britain and the British\\nEmpire to fight on, if necessary for years, if necessary alone.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n[13] During the last few days we have successfully brought off the great\\nmajority of the troops we had on the line of communication in France; and\\nseven-eighths of the troops we have sent to France since the beginning\\nof the war--that is to say, about 350,000 out of 400,000 men--are safely\\nback in this country. Others are still fighting with the French, and fighting\\nwith considerable success in their local encounters against the enemy.\\nWe have also brought back a great mass of stores, rifles and munitions\\nof all kinds which had been accumulated in France during the last nine\\nmonths.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n[14] We have, therefore, in this Island today a very large and powerful\\nmilitary force. This force comprises all our best-trained and our finest\\ntroops, including scores of thousands of those who have already measured\\ntheir quality against the Germans and found themselves at no disadvantage.\\nWe have under arms at the present time in this Island over a million and\\na quarter men. Behind these we have the Local Defense Volunteers, numbering\\nhalf a million, only a portion of whom, however, are yet armed with rifles\\nor other firearms. We have incorporated into our Defense Forces every man\\nfor whom we have a weapon. We expect very large additions to our weapons\\nin the near future, and in preparation for this we intend forthwith to\\ncall up, drill and train further large numbers. Those who are not called\\nup, or else are employed during the vast business of munitions production\\nin all its branches--and their ramifications are innumerable--will serve\\ntheir country best by remaining at their ordinary work until they receive\\ntheir summons. We have also over here Dominions armies. The Canadians had\\nactually landed in France, but have now been safely withdrawn, much disappointed,\\nbut in perfect order, with all their artillery and equipment. And these\\nvery high-class forces from the Dominions will now take part in the defense\\nof the Mother Country.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[15] Lest the account which I have given of these large forces should\\nraise the question: Why did they not take part in the great battle in France?\\nI must make it clear that, apart from the divisions training and organizing\\nat home, only twelve divisions were equipped to fight upon a scale which\\njustified their being sent abroad. And this was fully up to the number\\nwhich the French had been led to expect would be available in France at\\nthe ninth month of the war. The rest of our forces at home have a fighting\\nvalue for home defense which will, of course, steadily increase every week\\nthat passes. Thus, the invasion of Great Britain would at this time require\\nthe transportation across the sea of hostile armies on a very large scale,\\nand after they had been so transported they would have to be continually\\nmaintained with all the masses of munitions and supplies which are required\\nfor continuous battle--as continuous battle it will surely be.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n[16] Here is where we come to the Navy--and after all, we have a Navy.\\nSome people seem to forget that we have a Navy. We must remind them. For\\nthe last thirty years I have been concerned in discussions about the possibilities\\nof oversea invasion, and I took the responsibility on behalf of the Admiralty,\\nat the beginning of the last war, of allowing all regular troops to be\\nsent out of the country. That was a very serious step to take, because\\nour Territorials had only just been called up and were quite untrained.\\nTherefore, this Island was for several months particularly denuded of fighting\\ntroops. The Admiralty had confidence at that time in their ability to prevent\\na mass invasion even though at that time the Germans had a magnificent\\nbattle fleet in the proportion of 10 to 16, even though they were capable\\nof fighting a general engagement every day and any day, whereas now they\\nhave only a couple of heavy ships worth speaking of--the Scharnhorst and\\nthe Gneisenau. We are also told that the Italian Navy is to come out and\\ngain sea superiority in these waters. If they seriously intend it, I shall\\nonly say that we shall be delighted to offer Signor Mussolini a free and\\nsafeguarded passage through the Strait of Gibraltar in order that he may\\nplay the part to which he aspires. There is a general curiosity in the\\nBritish Fleet to find out whether the Italians are up to the level they\\nwere at in the last war or whether they have fallen off at all.                                                                                                                                                                                                                                                                                                                                                                                                                         \n[17] Therefore, it seems to me that as far as sea-borne invasion on a\\ngreat scale is concerned, we are far more capable of meeting it today than\\nwe were at many periods in the last war and during the early months of\\nthis war, before our other troops were trained, and while the B.E.F. had\\nproceeded abroad. Now, the Navy have never pretended to be able to prevent\\nraids by bodies of 5,000 or 10,000 men flung suddenly across and thrown\\nashore at several points on the coast some dark night or foggy morning.\\nThe efficacy of sea power, especially under modern conditions, depends\\nupon the invading force being of large size; It has to be of large size,\\nin view of our military strength, to be of any use. If it is of large size,\\nthen the Navy have something they can find and meet and, as it were, bite\\non. Now, we must remember that even five divisions, however lightly equipped,\\nwould require 200 to 250 ships, and with modern air reconnaissance and\\nphotography it would not be easy to collect such an armada, marshal it,\\nand conduct it across the sea without any powerful naval forces to escort\\nit; and there would be very great possibilities, to put it mildly, that\\nthis armada would be intercepted long before it reached the coast, and\\nall the men drowned in the sea or, at the worst blown to pieces with their\\nequipment while they were trying to land. We also have a great system of\\nminefields, recently strongly reinforced, through which we alone know the\\nchannels. If the enemy tries to sweep passages through these minefields,\\nit will be the task of the Navy to destroy the mine-sweepers and any other\\nforces employed to protect them. There should be no difficulty in this,\\nowing to our great superiority at sea.                                                                                                                                                         \n[18] Those are the regular, well-tested, well-proved arguments on which\\nwe have relied during many years in peace and war. But the question is\\nwhether there are any new methods by which those solid assurances can be\\ncircumvented. Odd as it may seem, some attention has been given to this\\nby the Admiralty, whose prime duty and responsibility is to destroy any\\nlarge sea-borne expedition before it reaches, or at the moment when it\\nreaches, these shores. It would not be a good thing for me to go into details\\nof this. It might suggest ideas to other people which they have not thought\\nof, and they would not be likely to give us any of their ideas in exchange.\\nAll I will say is that untiring vigilance and mind-searching must be devoted\\nto the subject, because the enemy is crafty and cunning and full of novel\\ntreacheries and stratagems. The House may be assured that the utmost ingenuity\\nis being displayed and imagination is being evoked from large numbers of\\ncompetent officers, well-trained in tactics and thoroughly up to date,\\nto measure and counterwork novel possibilities. Untiring vigilance and\\nuntiring searching of the mind is being, and must be, devoted to the subject,\\nbecause, remember, the enemy is crafty and there is no dirty trick he will\\nnot do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n[19] Some people will ask why, then, was it that the British Navy was\\nnot able to prevent the movement of a large army from Germany into Norway\\nacross the Skagerrak? But the conditions in the Channel and in the North\\nSea are in no way like those which prevail in the Skagerrak. In the Skagerrak,\\nbecause of the distance, we could give no air support to our surface ships,\\nand consequently, lying as we did close to the enemy's main air power,\\nwe were compelled to use only our submarines. We could not enforce the\\ndecisive blockade or interruption which is possible from surface vessels.\\nOur submarines took a heavy toll but could not, by themselves, prevent\\nthe invasion of Norway. In the Channel and in the North Sea, on the other\\nhand, our superior naval surface forces, aided by our submarines, will\\noperate with close and effective air assistance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n[20] This brings me, naturally, to the great question of invasion from\\nthe air, and of the impending struggle between the British and German Air\\nForces. It seems quite clear that no invasion on a scale beyond the capacity\\nof our land forces to crush speedily is likely to take place from the air\\nuntil our Air Force has been definitely overpowered. In the meantime, there\\nmay be raids by parachute troops and attempted descents of airborne soldiers.\\nWe should be able to give those gentry a warm reception both in the air\\nand on the ground, if they reach it in any condition to continue the dispute.\\nBut the great question is: Can we break Hitler's air weapon? Now, of course,\\nit is a very great pity that we have not got an Air Force at least equal\\nto that of the most powerful enemy within striking distance of these shores.\\nBut we have a very powerful Air Force which has proved itself far superior\\nin quality, both in men and in many types of machine, to what we have met\\nso far in the numerous and fierce air battles which have been fought with\\nthe Germans. In France, where we were at a considerable disadvantage and\\nlost many machines on the ground when they were standing round the aerodromes,\\nwe were accustomed to inflict in the air losses of as much as two and two-and-a-half\\nto one. In the fighting over Dunkirk, which was a sort of no-man's-land,\\nwe undoubtedly beat the German Air Force, and gained the mastery of the\\nlocal air, inflicting here a loss of three or four to one day after day.\\nAnyone who looks at the photographs which were published a week or so ago\\nof the re-embarkation, showing the masses of troops assembled on the beach\\nand forming an ideal target for hours at a time, must realize that this\\nre-embarkation would not have been possible unless the enemy had resigned\\nall hope of recovering air superiority at that time and at that place.\\n\n[21] In the defense of this Island the advantages to the defenders will\\nbe much greater than they were in the fighting around Dunkirk. We hope\\nto improve on the rate of three or four to one which was realized at Dunkirk;\\nand in addition all our injured machines and their crews which get down\\nsafely--and, surprisingly, a very great many injured machines and men do\\nget down safely in modern air fighting--all of these will fall, in an attack\\nupon these Islands, on friendly soil and live to fight another day; whereas\\nall the injured enemy machines and their complements will be total losses\\nas far as the war is concerned.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n[22] During the great battle in France, we gave very powerful and continuous\\naid to the French Army, both by fighters and bombers; but in spite of every\\nkind of pressure we never would allow the entire metropolitan fighter strength\\nof the Air Force to be consumed. This decision was painful, but it was\\nalso right, because the fortunes of the battle in France could not have\\nbeen decisively affected even if we had thrown in our entire fighter force.\\nThat battle was lost by the unfortunate strategical opening, by the extraordinary\\nand unforseen power of the armored columns, and by the great preponderance\\nof the German Army in numbers. Our fighter Air Force might easily have\\nbeen exhausted as a mere accident in that great struggle, and then we should\\nhave found ourselves at the present time in a very serious plight. But\\nas it is, I am happy to inform the House that our fighter strength is stronger\\nat the present time relatively to the Germans, who have suffered terrible\\nlosses, than it has ever been; and consequently we believe ourselves possessed\\nof the capacity to continue the war in the air under better conditions\\nthan we have ever experienced before. I look forward confidently to the\\nexploits of our fighter pilots--these splendid men, this brilliant youth--who\\nwill have the glory of saving their native land, their island home, and\\nall they love, from the most deadly of all attacks.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[23] There remains, of course, the danger of bombing attacks, which will\\ncertainly be made very soon upon us by the bomber forces of the enemy.\\nIt is true that the German bomber force is superior in numbers to ours;\\nbut we have a very large bomber force also, which we shall use to strike\\nat military targets in Germany without intermission. I do not at all underrate\\nthe severity of the ordeal which lies before us; but I believe our countrymen\\nwill show themselves capable of standing up to it, like the brave men of\\nBarcelona, and will be able to stand up to it, and carry on in spite of\\nit, at least as well as any other people in the world. Much will depend\\nupon this; every man and every woman will have the chance to show the finest\\nqualities of their race, and render the highest service to their cause.\\nFor all of us, at this time, whatever our sphere, our station, our occupation\\nor our duties, it will be a help to remember the famous lines:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n[24] He nothing common did or mean, Upon that memorable scene.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n[25] I have thought it right upon this occasion to give the House and\\nthe country some indication of the solid, practical grounds upon which\\nwe base our inflexible resolve to continue the war. There are a good many\\npeople who say, 'Never mind. Win or lose, sink or swim, better die than\\nsubmit to tyranny--and such a tyranny.' And I do not dissociate myself\\nfrom them. But I can assure them that our professional advisers of the\\nthree Services unitedly advise that we should carry on the war, and that\\nthere are good and reasonable hopes of final victory. We have fully informed\\nand consulted all the self-governing Dominions, these great communities\\nfar beyond the oceans who have been built up on our laws and on our civilization,\\nand who are absolutely free to choose their course, but are absolutely\\ndevoted to the ancient Motherland, and who feel themselves inspired by\\nthe same emotions which lead me to stake our all upon duty and honor. We\\nhave fully consulted them, and I have received from their Prime Ministers,\\nMr. Mackenzie King of Canada, Mr. Menzies of Australia, Mr. Fraser of New\\nZealand, and General Smuts of South Africa--that wonderful man, with his\\nimmense profound mind, and his eye watching from a distance the whole panorama\\nof European affairs--I have received from all these eminent men, who all\\nhave Governments behind them elected on wide franchises, who are all there\\nbecause they represent the will of their people, messages couched in the\\nmost moving terms in which they endorse our decision to fight on, and declare\\nthemselves ready to share our fortunes and to persevere to the end. That\\nis what we are going to do.                                                                                                                                                                                                                                  \n[26] We may now ask ourselves: In what way has our position worsened since\\nthe beginning of the war? It has worsened by the fact that the Germans\\nhave conquered a large part of the coast line of Western Europe, and many\\nsmall countries have been overrun by them. This aggravates the possibilities\\nof air attack and adds to our naval preoccupations. It in no way diminishes,\\nbut on the contrary definitely increases, the power of our long-distance\\nblockade. Similarly, the entrance of Italy into the war increases the power\\nof our long-distance blockade. We have stopped the worst leak by that.\\nWe do not know whether military resistance will come to an end in France\\nor not, but should it do so, then of course the Germans will be able to\\nconcentrate their forces, both military and industrial, upon us. But for\\nthe reasons I have given to the House these will not be found so easy to\\napply. If invasion has become more imminent, as no doubt it has, we, being\\nrelieved from the task of maintaining a large army in France, have far\\nlarger and more efficient forces to meet it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[27] If Hitler can bring under his despotic control the industries of\\nthe countries he has conquered, this will add greatly to his already vast\\narmament output. On the other hand, this will not happen immediately, and\\nwe are now assured of immense, continuous and increasing support in supplies\\nand munitions of all kinds from the United States; and especially of aeroplanes\\nand pilots from the Dominions and across the oceans coming from regions\\nwhich are beyond the reach of enemy bombers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[28] I do not see how any of these factors can operate to our detriment\\non balance before the winter comes; and the winter will impose a strain\\nupon the Nazi regime, with almost all Europe writhing and starving under\\nits cruel heel, which, for all their ruthlessness, will run them very hard.\\nWe must not forget that from the moment when we declared war on the 3rd\\nSeptember it was always possible for Germany to turn all her Air Force\\nupon this country, together with any other devices of invasion she might\\nconceive, and that France could have done little or nothing to prevent\\nher doing so. We have, therefore, lived under this danger, in principle\\nand in a slightly modified form, during all these months. In the meanwhile,\\nhowever, we have enormously improved our methods of defense, and we have\\nlearned what we had no right to assume at the beginning, namely, that the\\nindividual aircraft and the individual British pilot have a sure and definite\\nsuperiority. Therefore, in casting up this dread balance sheet and contemplating\\nour dangers with a disillusioned eye, I see great reason for intense vigilance\\nand exertion, but none whatever for panic or despair.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n[29] During the first four years of the last war the Allies experienced\\nnothing but disaster and disappointment. That was our constant fear: one\\nblow after another, terrible losses, frightful dangers. Everything miscarried.\\nAnd yet at the end of those four years the morale of the Allies was higher\\nthan that of the Germans, who had moved from one aggressive triumph to\\nanother, and who stood everywhere triumphant invaders of the lands into\\nwhich they had broken. During that war we repeatedly asked ourselves the\\nquestion: 'How are we going to win?' And no one was able ever to answer\\nit with much precision, until at the end, quite suddenly, quite unexpectedly,\\nour terrible foe collapsed before us, and we were so glutted with victory\\nthat in our folly we threw it away.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[30] We do not yet know what will happen in France or whether the French\\nresistance will be prolonged, both in France and in the French Empire overseas.\\nThe French Government will be throwing away great opportunities and casting\\nadrift their future if they do not continue the war in accordance with\\ntheir treaty obligations, from which we have not felt able to release them.\\nThe House will have read the historic declaration in which, at the desire\\nof many Frenchmen--and of our own hearts--we have proclaimed our willingness\\nat the darkest hour in French history to conclude a union of common citizenship\\nin this struggle. However matters may go in France or with the French Government,\\nor other French Governments, we in this Island and in the British Empire\\nwill never lose our sense of comradeship with the French people. If we\\nare now called upon to endure what they have been suffering, we shall emulate\\ntheir courage, and if final victory rewards our toils they shall share\\nthe gains, aye, and freedom shall be restored to all. We abate nothing\\nof our just demands; not one jot or tittle do we recede. Czechs, Poles,\\nNorwegians, Dutch, Belgians have joined their causes to our own. All these\\nshall be restored.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n[31] What General Weygand called the Battle of France is over. I expect\\nthat the Battle of Britain is about to begin. Upon this battle depends\\nthe survival of Christian civilization. Upon it depends our own British\\nlife, and the long continuity of our institutions and our Empire. The whole\\nfury and might of the enemy must very soon be turned on us.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n[32] Hitler knows that he will have to break us in this Island or lose\\nthe war. If we can stand up to him, all Europe may be free and the life\\nof the world may move forward into broad, sunlit uplands. But if we fail,\\nthen the whole world, including the United States, including all that we\\nhave known and cared for, will sink into the abyss of a new Dark Age made\\nmore sinister, and perhaps more protracted, by the lights of perverted\\nscience.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[33] Let us therefore brace ourselves to our duties, and so bear ourselves\\nthat if the British Empire and its Commonwealth last for a thousand years,\\nmen will still say, 'This was their finest hour.'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n[34] Winston Churchill - June 18, 1940                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[35]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n[36] The History Place - Great Speeches Collection\\n  See also: The History Place - Defeat of Hitler - Britain Stands Alone                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[37] [ The History Place \\n        Main Page | American \\n        Revolution | Abraham Lincoln | \\n        American Civil War | Child \\n        Labor in America 1908-1912 | U.S. \\n        in World War II in the Pacific | John \\n        F. Kennedy Photo History | Vietnam \\n        War | First World War | The Rise of Adolf \\n        Hitler | Triumph of \\n        Hitler | Defeat of Hitler | Hitler Youth \\n        | World War II in Europe \\n        | Holocaust Timeline \\n        | 20th Century Genocide \\n        | Irish Potato Famine \\n        | This Month in History \\n        | Books on Hitler's Germany | History \\n      Videos | Hollywood's Best History Movies ]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n[38] Terms of use: Private home/school\\nnon-commercial, non-Internet re-usage only is allowed of any text, graphics,\\nphotos, audio clips, other electronic files or materials from The History\\nPlace.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n\n# Turn all words to lower case\nwords.corpus <- tm_map(words.corpus, content_transformer(tolower))\n\nWarning in tm_map.SimpleCorpus(words.corpus, content_transformer(tolower)):\ntransformation drops documents\n\n# Remove punctuations, numbers\nwords.corpus <- tm_map(words.corpus, removePunctuation)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removePunctuation): transformation\ndrops documents\n\nwords.corpus <- tm_map(words.corpus, removeNumbers)\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeNumbers): transformation\ndrops documents\n\n# How about stopwords, then uniform bag of words created\n\nwords.corpus <- tm_map(words.corpus, removeWords, stopwords(\"english\"))\n\nWarning in tm_map.SimpleCorpus(words.corpus, removeWords, stopwords(\"english\")):\ntransformation drops documents\n\n# Create Term Document Matrix\n\ntdm <- TermDocumentMatrix(words.corpus)\ninspect(tdm)\n\n<<TermDocumentMatrix (terms: 1178, documents: 38)>>\nNon-/sparse entries: 1948/42816\nSparsity           : 96%\nMaximal term length: 15\nWeighting          : term frequency (tf)\nSample             :\n         Docs\nTerms     11 14 16 17 18 20 22 25 30 9\n  air      0  0  0  1  0 13  3  0  0 0\n  battle   0  0  1  0  0  0  3  0  0 2\n  british  0  0  1  0  0  1  0  0  1 3\n  force    0  2  0  1  0  4  3  0  0 1\n  france   0  1  0  0  0  1  2  0  3 2\n  french   0  0  0  0  0  0  1  0  7 6\n  great    0  0  0  4  0  3  3  1  1 0\n  large    0  3  0  3  2  0  0  0  0 0\n  upon     0  0  0  1  0  0  0  3  1 1\n  war      1  0  2  2  1  0  1  2  1 0\n\nm <- as.matrix(tdm)\nwordCounts <- rowSums(m)\nwordCounts <- sort(wordCounts, decreasing=TRUE)\nhead(wordCounts)\n\n   war    air france  great french   upon \n    24     23     20     20     19     16 \n\n# Create Wordcloud\ncloudFrame<-data.frame(word=names(wordCounts),freq=wordCounts)\n\nset.seed(1234)\nwordcloud(cloudFrame$word,cloudFrame$freq)\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): french could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): british could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): large could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): country could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): also could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): worst could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): make could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): army could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): weeks could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): going could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): support could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): whole could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): injured could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): three could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): divisions could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): present could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): beginning could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): time could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): called could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): possibilities could not\nbe fit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): france could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): without could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): come could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): quite could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): war could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): duty could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): enemy could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): battle could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): fighting could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): hitler could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): may could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): men could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): absolutely could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): munitions could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): made could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): conditions could not be\nfit on page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): whether could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): just could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): future could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): place could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): even could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): many could not be fit on\npage. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): alone could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): modern could not be fit\non page. It will not be plotted.\n\n\nWarning in wordcloud(cloudFrame$word, cloudFrame$freq): question could not be\nfit on page. It will not be plotted.\n\n\n\n\nwordcloud(names(wordCounts),wordCounts, min.freq=3,random.order=FALSE, max.words=500,scale=c(3,.5), rot.per=0.35,colors=brewer.pal(8,\"Dark2\"))\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 3, random.order =\nFALSE, : injured could not be fit on page. It will not be plotted.\n\n\nWarning in wordcloud(names(wordCounts), wordCounts, min.freq = 3, random.order =\nFALSE, : bomber could not be fit on page. It will not be plotted."
  },
  {
    "objectID": "assign03_6302.html",
    "href": "assign03_6302.html",
    "title": "EPPS 6302 Assignment 3",
    "section": "",
    "text": "# Data Methods: Social media (Twitter) data\n# Sample program for using rtweet, sentiment analysis\n# Use vignette(\"auth\", package = \"rtweet\") for authentication\n# Documentation: vignette(\"intro\", package = \"rtweet\")\n# GitHub: https://github.com/mkearney/rtweet\n# [Bob Rudis 21 Recipes for Mining Twitter Data with rtweet](https://rud.is/books/21-recipes/)\n\nrm(list=ls())\n\nlibrary(rtweet)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ tibble  3.1.6      ✔ dplyr   1.0.10\n✔ tidyr   1.2.0      ✔ stringr 1.4.0 \n✔ readr   2.1.1      ✔ forcats 0.5.1 \n✔ purrr   0.3.4      \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()  masks stats::filter()\n✖ purrr::flatten() masks rtweet::flatten()\n✖ dplyr::lag()     masks stats::lag()\n\nlibrary(quanteda)\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"mMatrix\"; definition not updated\n\n\nWarning in .recacheSubclasses(def@className, def, env): undefined subclass\n\"packedMatrix\" of class \"replValueSp\"; definition not updated\n\n\nPackage version: 3.2.3\nUnicode version: 14.0\nICU version: 70.1\nParallel computing: 8 of 8 threads used.\nSee https://quanteda.io for tutorials and examples.\n\nlibrary(quanteda.textmodels)\nlibrary(quanteda.textplots)\nlibrary(readr)\n\n# Set up authentication using own Twitter account\n# will save credentials to local drive as default.rds\nSys.setenv(TWITTER_BEARER = \"AAAAAAAAAAAAAAAAAAAAAMsxhAEAAAAAzBUGoUHZtZp5Ax2OtJaAObG4rec%3DLGMtinMdRqtP9xU5NjFY3KVhZAyXM160sEyTbP5YTZr4T3MT0m\")\n\nparams <- list(`user.fields` = 'description',\n               `expansions` = 'pinned_tweet_id')\n\nauth_setup_default()\n\nUsing default authentication available.\nReading auth from '/Users/sami_manuel/Library/Preferences/org.R-project.R/R/rtweet/default.rds'\n\n## search for 500 tweets of \"Joe Biden\" in English\njbt <- rtweet::search_tweets(q = \"JoeBiden\", n = 500, lang = \"en\", retryonratelimit = TRUE)\n\n#i. Most likes\nmax(jbt$favorite_count)\n\n[1] 64787\n\n#ii. Most Retweets\nmax(jbt$retweet_count)\n\n[1] 18094\n\n#ii. Most Replies\nmax(jbt$reply_count)\n\n[1] NA\n\n# analysis of Joe Biden tweets\njbt_twt = jbt$text\njbt_toks = tokens(jbt_twt)\njbttwtdfm <- dfm(jbt_toks)\n\n# JBT Latent Semantic Analysis\njbt_sum_lsa <- textmodel_lsa(jbttwtdfm)\nsummary(jbt_sum_lsa)\n\n                Length  Class     Mode   \nsk                   10 -none-    numeric\ndocs               4820 -none-    numeric\nfeatures          21980 -none-    numeric\nmatrix_low_rank 1059436 -none-    numeric\ndata            1059436 dgCMatrix S4     \n\njbt_tweet_dfm <- tokens(jbt_twt, remove_punct = TRUE) %>%\n  dfm()\nhead(jbt_tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 2,179 features (99.15% sparse) and 0 docvars.\n       features\ndocs    @joebiden we're waiting for your response to execution of\n  text1         1     1       1   1    1        1  2         2  1\n  text2         0     0       0   1    0        0  0         0  0\n  text3         1     0       0   2    0        0  0         0  0\n  text4         1     0       0   0    0        0  0         0  0\n  text5         1     0       0   2    0        0  0         0  0\n  text6         1     0       0   0    0        0  0         0  0\n       features\ndocs    #mohsenshekari\n  text1              1\n  text2              0\n  text3              0\n  text4              0\n  text5              0\n  text6              0\n[ reached max_nfeat ... 2,169 more features ]\n\njbt_tag_dfm <- dfm_select(jbt_tweet_dfm, pattern = \"#*\")\njbt_toptag <- names(topfeatures(jbt_tag_dfm, 50))\nhead(jbt_toptag, 10)\n\n [1] \"#7️⃣6️⃣5️⃣daysoftigraygenocide\" \"#joebiden\"               \n [3] \"#tigraygenocide\"          \"#766daysoftigraygenocide\"\n [5] \"#tigrayan\"                \"#brittneygriner\"         \n [7] \"#paulwhelan\"              \"#donaldtrump\"            \n [9] \"#viktorbout\"              \"#bnnus\"                  \n\n## search for 500 tweets of \"PLA Taiwan\" in English\nPLA <- rtweet::search_tweets(q = \"PLA Taiwan\", n = 500, lang = \"en\", retryonratelimit = TRUE)\n\n# analysis of tweets\nPLA_twt = PLA$text\nPLA_toks = tokens(PLA_twt)\nPLAtwtdfm <- dfm(PLA_toks)\n\n# Latent Semantic Analysis\nPLA_sum_lsa <- textmodel_lsa(PLAtwtdfm)\nsummary(PLA_sum_lsa)\n\n                Length Class     Mode   \nsk                  10 -none-    numeric\ndocs              5000 -none-    numeric\nfeatures         10080 -none-    numeric\nmatrix_low_rank 504000 -none-    numeric\ndata            504000 dgCMatrix S4     \n\nPLA_tweet_dfm <- tokens(PLA_twt, remove_punct = TRUE) %>%\n  dfm()\nhead(PLA_tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 992 features (97.08% sparse) and 0 docvars.\n       features\ndocs    24 pla aircraft and 4 plan vessels around taiwan were\n  text1  1   1        2   3 1    1       2      1      1    1\n  text2  0   1        1   2 0    0       0      0      1    0\n  text3  0   1        1   1 1    1       1      1      1    1\n  text4  0   1        1   1 1    1       1      1      1    1\n  text5  0   1        1   1 1    1       1      1      1    1\n  text6  0   1        1   1 1    1       1      1      1    1\n[ reached max_nfeat ... 982 more features ]\n\nPLA_tag_dfm <- dfm_select(PLA_tweet_dfm, pattern = \"#*\")\nPLA_toptag <- names(topfeatures(PLA_tag_dfm, 50))\nhead(PLA_toptag, 10)\n\n [1] \"#pla\"                    \"#taiwan\"                \n [3] \"#ccp\"                    \"#china\"                 \n [5] \"#taiwanstraitmedianline\" \"#ai\"                    \n [7] \"#ml\"                     \"#artificialintelligence\"\n [9] \"#machinelearning\"        \"#datascience\"           \n\n## search for 500 tweets of \"BLM\" in English\nBLM <- rtweet::search_tweets(q = \"Black Lives Matter\", n = 500, lang = \"en\", retryonratelimit = TRUE)\n\n# analysis of tweets\nBLM_twt = BLM$text\nBLM_toks = tokens(BLM_twt)\nBLMtwtdfm <- dfm(BLM_toks)\n\n# Latent Semantic Analysis\nBLM_sum_lsa <- textmodel_lsa(BLMtwtdfm)\nsummary(BLM_sum_lsa)\n\n                Length  Class     Mode   \nsk                   10 -none-    numeric\ndocs               4380 -none-    numeric\nfeatures          24130 -none-    numeric\nmatrix_low_rank 1056894 -none-    numeric\ndata            1056894 dgCMatrix S4     \n\nBLM_tweet_dfm <- tokens(BLM_twt, remove_punct = TRUE) %>%\n  dfm()\nhead(BLM_tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 2,395 features (98.95% sparse) and 0 docvars.\n       features\ndocs    the major problem with israel is young generation of black\n  text1   5     1       1    2      2  1     1          1  2     3\n  text2   2     0       0    0      1  1     1          0  1     4\n  text3   0     0       0    0      0  0     0          0  0     1\n  text4   1     0       0    0      0  0     0          0  1     0\n  text5   1     0       0    0      0  0     0          0  0     1\n  text6   0     0       0    0      0  0     0          0  0     1\n[ reached max_nfeat ... 2,385 more features ]\n\nBLM_tag_dfm <- dfm_select(BLM_tweet_dfm, pattern = \"#*\")\nBLM_toptag <- names(topfeatures(BLM_tag_dfm, 50))\nhead(BLM_toptag, 10)\n\n [1] \"#bnwo\"                  \"#blacklivesmatter\"      \"#blm\"                  \n [4] \"#brittneygriner\"        \"#imagainstantisemitism\" \"#nowplaying\"           \n [7] \"#dailyapology\"          \"#visitourhomeofhope\"    \"#saytheirnames\"        \n[10] \"#babecock\"             \n\n## search for 500 tweets of \"COVID\" in English\nCOVID <- rtweet::search_tweets(q = \"COVID\", n = 500, lang = \"en\", retryonratelimit = TRUE)\n\n# analysis of tweets\nCOVID_twt = COVID$text\nCOVID_toks = tokens(COVID_twt)\nCOVIDtwtdfm <- dfm(COVID_toks)\n\n# Latent Semantic Analysis\nCOVID_sum_lsa <- textmodel_lsa(COVIDtwtdfm)\nsummary(COVID_sum_lsa)\n\n                Length  Class     Mode   \nsk                   10 -none-    numeric\ndocs               5000 -none-    numeric\nfeatures          32880 -none-    numeric\nmatrix_low_rank 1644000 -none-    numeric\ndata            1644000 dgCMatrix S4     \n\nCOVID_tweet_dfm <- tokens(COVID_twt, remove_punct = TRUE) %>%\n  dfm()\nhead(COVID_tweet_dfm)\n\nDocument-feature matrix of: 6 documents, 3,269 features (99.31% sparse) and 0 docvars.\n       features\ndocs    3 take for example stanford's dr jay bhattacharya @drjbhattacharya who\n  text1 1    1   1       1          1  1   1            1                1   1\n  text2 0    0   0       0          0  0   0            0                0   1\n  text3 0    0   1       0          0  0   0            0                0   0\n  text4 0    0   0       0          0  0   0            0                0   1\n  text5 0    0   0       0          0  0   0            0                0   0\n  text6 0    0   0       0          0  0   0            0                0   0\n[ reached max_nfeat ... 3,259 more features ]\n\nCOVID_tag_dfm <- dfm_select(COVID_tweet_dfm, pattern = \"#*\")\nCOVID_toptag <- names(topfeatures(COVID_tag_dfm, 50))\nhead(COVID_toptag, 10)\n\n [1] \"#covid\"              \"#covid19\"            \"#diedsuddenly\"      \n [4] \"#039\"                \"#corona\"             \"#nationalsecurity\"  \n [7] \"#shippingplatform\"   \"#bnnus\"              \"#conspiracytheories\"\n[10] \"#lo\""
  }
]